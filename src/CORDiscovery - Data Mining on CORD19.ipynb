{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:05:03.816670Z",
     "start_time": "2020-05-08T14:05:03.810672Z"
    }
   },
   "source": [
    "# Phase I - Data Preparation and Modelling\n",
    "<hr>\n",
    "This is a <b>one time process</b> to generate vector embeddings for the document corpus using ensemble approach and store the model objects/configuration states for the searching purposes. There are 3 stages in this phase - <br>\n",
    "1. Data Preparation and Wrangling <br>\n",
    "2. Generation of embeddings for the document corpus for different techniques in ensemble approach<br>\n",
    "3. Saving the model objects and configuration for later use<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T08:41:07.004967Z",
     "start_time": "2020-05-08T08:41:06.999962Z"
    }
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T11:35:07.714919Z",
     "start_time": "2020-05-08T11:35:07.707882Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np \n",
    "import sys\n",
    "import os \n",
    "import nltk\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import scipy\n",
    "import gensim\n",
    "from tqdm.auto import tqdm\n",
    "from pprint import pprint\n",
    "\n",
    "from flask import Flask, render_template, jsonify, request\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn import mixture\n",
    "\n",
    "from scipy import spatial\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import *\n",
    "from summarizer import Summarizer\n",
    "from gensim.summarization.summarizer import summarize\n",
    "\n",
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import bulk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the nltk library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T11:35:09.079896Z",
     "start_time": "2020-05-08T11:35:08.964836Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nltk.data.path.append('../bin/')\n",
    "nltk.download('stopwords',download_dir='../bin/', quiet=True)\n",
    "nltk.download('punkt',download_dir='../bin/', quiet=True)\n",
    "stop_words = stopwords.words('english')\n",
    "nltk.download('averaged_perceptron_tagger',download_dir='../bin/', quiet=True)\n",
    "nltk.download('wordnet',download_dir='../bin/', quiet=True)\n",
    "nltk.download('omw',download_dir='../bin/', quiet=True)\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T11:47:59.670010Z",
     "start_time": "2020-05-08T11:47:59.658964Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#To clean the abstracts\n",
    "def clean_docs(doc_list):\n",
    "\n",
    "    doc_df = pd.DataFrame({'document':doc_list})\n",
    "\n",
    "    #Clean the data\n",
    "    # removing everything except alphabets`\n",
    "    doc_df['clean_doc'] = doc_df['document'].str.replace(\"[^a-zA-Z#]\", \" \")\n",
    "\n",
    "    # removing short wordsstop_words = stopwords.words('english')\n",
    "    doc_df['clean_doc'] = doc_df['clean_doc'].apply(lambda x: ' '.join([w for w in x.split() if len(w)>3]))\n",
    "\n",
    "    # make all text lowercase\n",
    "    doc_df['clean_doc'] = doc_df['clean_doc'].apply(lambda x: x.lower())\n",
    "\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    # tokenization\n",
    "    tokenized_doc = doc_df['clean_doc'].apply(lambda x: x.split())\n",
    "\n",
    "    # remove stop-words\n",
    "    tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "    # de-tokenization\n",
    "    detokenized_doc = []\n",
    "    for i in range(len(doc_df)):\n",
    "\n",
    "        try:\n",
    "            t = ' '.join(tokenized_doc[i])\n",
    "            detokenized_doc.append(t)\n",
    "        except:\n",
    "            print(f'Can not put {tokenized_doc[i]} back together')\n",
    "            detokenized_doc.append('')\n",
    "\n",
    "\n",
    "    detokenized_doc = np.array(detokenized_doc)\n",
    "\n",
    "    return detokenized_doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data\"></a>\n",
    "## Data loading and Cleaning\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T08:45:35.611010Z",
     "start_time": "2020-05-08T08:45:35.607005Z"
    }
   },
   "source": [
    "### Cleaning the abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T11:37:20.803647Z",
     "start_time": "2020-05-08T11:37:16.629731Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/IPython/core/interactiveshell.py:3062: DtypeWarning: Columns (5,13,14,16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "#load the csv sources\n",
    "raw_md_data = pd.read_csv('../data/metadata.csv')\n",
    "raw_md_data.drop_duplicates(['abstract'], inplace=True) #drop duplicates by abstract\n",
    "raw_md_data.dropna(subset=['abstract'], inplace=True) #remove missing abstracts\n",
    "\n",
    "raw_md_data.drop_duplicates(['title'], inplace=True) #drop duplicates by title\n",
    "raw_md_data.dropna(subset=['title'], inplace=True) #remove missing titles\n",
    "\n",
    "#Remove quasi-duplicate titles\n",
    "raw_md_data['clean_title'] = clean_docs(raw_md_data['title'].tolist())\n",
    "raw_md_data.drop_duplicates(['clean_title'], inplace=True)\n",
    "\n",
    "#Select required columns\n",
    "df = raw_md_data[['cord_uid', 'title', 'abstract']]\n",
    "#store as new file\n",
    "df.to_csv('../data/cleaned_abstracts.csv', header=False, index=False)\n",
    "\n",
    "#list of abstracts (document corpus)\n",
    "clean_abstracts = df['abstract']\n",
    "doc_corpus = list(clean_abstracts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert data into JSON format for ingestion into Elasticsearch index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T11:47:16.819810Z",
     "start_time": "2020-05-08T11:47:13.296783Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "csvfile = open('../data/cleaned_abstracts.csv', 'r', encoding='utf-8')\n",
    "jsonfile = open('../data/cleaned_abstracts.json', 'w')\n",
    "\n",
    "fieldnames = (\"cord_uid\", \"title\", \"abstract\") #corresponding to the required columns\n",
    "reader = csv.DictReader(csvfile, fieldnames)\n",
    "for row in reader:\n",
    "    json.dump(row, jsonfile)\n",
    "    jsonfile.write('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T08:47:23.059599Z",
     "start_time": "2020-05-08T08:47:23.056595Z"
    }
   },
   "source": [
    "<a id=\"Modelling and embedding generation\"></a>\n",
    "## Modelling and embedding generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Topic-Modeling\"></a>\n",
    "### Topic Modeling with Cosine distance\n",
    "<hr>\n",
    "Topic modeling is a NLP unsupervised technique for assigning particular words to clusters. These clusters can be thought of as word clouds and contain similar terms. Latent semantic analysis (LSA) and latent Dirichlet allocation (LDA) are two of the most popular topic modeling methods. Here we use LSA for its computational speed, but LDA could also be considered here. Once again we use Cosine distance with the results of the topic modeling.\n",
    "<img src=\"https://i.ibb.co/23sp1Gb/tm-abstracts.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T11:48:04.530919Z",
     "start_time": "2020-05-08T11:48:04.521923Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "NUM_TOPICS= 100\n",
    "\n",
    "def make_tm_output(doc_list,num_tf_idf_features=1000,num_compons=NUM_TOPICS):\n",
    "    \"\"\"\n",
    "    Make output for topic modeling\n",
    "    :param doc_list:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    detokenized_doc = clean_docs(doc_list)\n",
    "\n",
    "    # #Run the model\n",
    "    vectorizer = TfidfVectorizer(stop_words='english',\n",
    "    max_features= num_tf_idf_features, # keep top 1000 terms\n",
    "    max_df = 0.25,\n",
    "    smooth_idf=True)\n",
    "\n",
    "\n",
    "    tfidf_output = vectorizer.fit_transform(detokenized_doc)\n",
    "\n",
    "    # SVD represent documents and terms in vectors\n",
    "    svd_model = TruncatedSVD(n_components=num_compons, algorithm='randomized', n_iter=100, random_state=42)\n",
    "\n",
    "    svd_model.fit(tfidf_output)\n",
    "\n",
    "    tm_output = svd_model.fit_transform(tfidf_output)\n",
    "    return tm_output, vectorizer, svd_model, tfidf_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T11:52:41.267852Z",
     "start_time": "2020-05-08T11:48:08.655883Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1355.4940433502197 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "tm_output,vectorizer,svd_model,tfidf_output = make_tm_output(doc_corpus,num_compons=NUM_TOPICS)\n",
    "print('Time taken:', time.time()-start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save models and vectors for the corpus for topic modeling\n",
    "with open('../models/tm_vectors.pkl', 'wb') as f:\n",
    "    pickle.dump(tm_output,f)\n",
    "    \n",
    "with open('../models/tm_vectorizer.pkl', 'wb') as f:\n",
    "    pickle.dump(vectorizer,f)\n",
    "\n",
    "with open('../models/tm_svd_model.pkl', 'wb') as f:\n",
    "    pickle.dump(svd_model,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"TF-IDF\"></a>\n",
    "### TF-IDF with Cosine distance\n",
    "<hr>\n",
    "Term Frequency-Inverse Document Frequency (TF-IDF) is a basic NLP method that determines the importance of an individual word relative to a document. That is, words are weighted based on how often then appear in a document and then inversely weighted based on how often they appear across a collection of documents.  Cosine distance (https://en.wikipedia.org/wiki/Cosine_similarity) is a common distance measure in the NLP literature and is used with many of the methods presented here. Cosine distance measures the difference in orientation. Thus, it is possible that two sentences or documents are far apart in Euclidean space but actually have similar orientations and are similar according to Cosine distance.\n",
    "<a name=\"some-id\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T11:57:28.917901Z",
     "start_time": "2020-05-08T11:57:28.893911Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def tfidf_bow(doc_list):\n",
    "    #clean the docs\n",
    "    detokenized_doc = clean_docs(doc_list)\n",
    "    gen_docs = [[w.lower() for w in word_tokenize(text)] for text in detokenized_doc]\n",
    "\n",
    "    # create the dictionary\n",
    "    dictionary = gensim.corpora.Dictionary(gen_docs)\n",
    "\n",
    "    # Create bag of words\n",
    "    corpus = [dictionary.doc2bow(gen_doc) for gen_doc in gen_docs]\n",
    "    tf_idf = gensim.models.TfidfModel(corpus)\n",
    "    corpus_tfidf = tf_idf[corpus]\n",
    "    lsi = gensim.models.LsiModel(corpus_tfidf, id2word=dictionary, num_topics=300)\n",
    "    corpus_lsi = lsi[corpus_tfidf]\n",
    "    return dictionary, lsi, corpus_lsi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T12:03:44.554251Z",
     "start_time": "2020-05-08T11:57:31.249891Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 12:54:15.540522 140392763574080 dictionary.py:205] adding document #0 to Dictionary(0 unique tokens: [])\n",
      "I0703 12:54:17.418383 140392763574080 dictionary.py:205] adding document #10000 to Dictionary(47051 unique tokens: ['abdulaziz', 'acquired', 'admission', 'affected', 'arabia']...)\n",
      "I0703 12:54:19.173717 140392763574080 dictionary.py:205] adding document #20000 to Dictionary(72989 unique tokens: ['abdulaziz', 'acquired', 'admission', 'affected', 'arabia']...)\n",
      "I0703 12:54:21.081262 140392763574080 dictionary.py:205] adding document #30000 to Dictionary(84130 unique tokens: ['abdulaziz', 'acquired', 'admission', 'affected', 'arabia']...)\n",
      "I0703 12:54:23.039579 140392763574080 dictionary.py:205] adding document #40000 to Dictionary(92947 unique tokens: ['abdulaziz', 'acquired', 'admission', 'affected', 'arabia']...)\n",
      "I0703 12:54:25.002710 140392763574080 dictionary.py:205] adding document #50000 to Dictionary(101059 unique tokens: ['abdulaziz', 'acquired', 'admission', 'affected', 'arabia']...)\n",
      "I0703 12:54:26.792050 140392763574080 dictionary.py:205] adding document #60000 to Dictionary(108281 unique tokens: ['abdulaziz', 'acquired', 'admission', 'affected', 'arabia']...)\n",
      "I0703 12:54:28.567702 140392763574080 dictionary.py:205] adding document #70000 to Dictionary(115734 unique tokens: ['abdulaziz', 'acquired', 'admission', 'affected', 'arabia']...)\n",
      "I0703 12:54:30.397915 140392763574080 dictionary.py:205] adding document #80000 to Dictionary(126484 unique tokens: ['abdulaziz', 'acquired', 'admission', 'affected', 'arabia']...)\n",
      "I0703 12:54:32.147481 140392763574080 dictionary.py:205] adding document #90000 to Dictionary(134795 unique tokens: ['abdulaziz', 'acquired', 'admission', 'affected', 'arabia']...)\n",
      "I0703 12:54:33.953731 140392763574080 dictionary.py:205] adding document #100000 to Dictionary(141902 unique tokens: ['abdulaziz', 'acquired', 'admission', 'affected', 'arabia']...)\n",
      "I0703 12:54:34.601848 140392763574080 dictionary.py:210] built Dictionary(144354 unique tokens: ['abdulaziz', 'acquired', 'admission', 'affected', 'arabia']...) from 103482 documents (total 11867339 corpus positions)\n",
      "I0703 12:54:45.673514 140392763574080 tfidfmodel.py:454] collecting document frequencies\n",
      "I0703 12:54:45.674752 140392763574080 tfidfmodel.py:460] PROGRESS: processing document #0\n",
      "I0703 12:54:45.923480 140392763574080 tfidfmodel.py:460] PROGRESS: processing document #10000\n",
      "I0703 12:54:46.173645 140392763574080 tfidfmodel.py:460] PROGRESS: processing document #20000\n",
      "I0703 12:54:46.456550 140392763574080 tfidfmodel.py:460] PROGRESS: processing document #30000\n",
      "I0703 12:54:46.732511 140392763574080 tfidfmodel.py:460] PROGRESS: processing document #40000\n",
      "I0703 12:54:47.014802 140392763574080 tfidfmodel.py:460] PROGRESS: processing document #50000\n",
      "I0703 12:54:47.274631 140392763574080 tfidfmodel.py:460] PROGRESS: processing document #60000\n",
      "I0703 12:54:47.529699 140392763574080 tfidfmodel.py:460] PROGRESS: processing document #70000\n",
      "I0703 12:54:47.791618 140392763574080 tfidfmodel.py:460] PROGRESS: processing document #80000\n",
      "I0703 12:54:48.053282 140392763574080 tfidfmodel.py:460] PROGRESS: processing document #90000\n",
      "I0703 12:54:48.315716 140392763574080 tfidfmodel.py:460] PROGRESS: processing document #100000\n",
      "I0703 12:54:48.416537 140392763574080 tfidfmodel.py:471] calculating IDF weights for 103482 documents and 144354 features (8520167 matrix non-zeros)\n",
      "I0703 12:54:49.162815 140392763574080 lsimodel.py:420] using serial LSI version on this node\n",
      "I0703 12:54:49.163832 140392763574080 lsimodel.py:466] updating model with new documents\n",
      "I0703 12:55:04.362804 140392763574080 lsimodel.py:492] preparing a new chunk of documents\n",
      "I0703 12:55:05.033000 140392763574080 lsimodel.py:912] using 100 extra samples and 2 power iterations\n",
      "I0703 12:55:05.033986 140392763574080 lsimodel.py:920] 1st phase: constructing (144354, 400) action matrix\n",
      "I0703 12:55:06.581147 140392763574080 lsimodel.py:935] orthonormalizing (144354, 400) action matrix\n",
      "I0703 12:55:27.596315 140392763574080 lsimodel.py:987] 2nd phase: running dense svd on (400, 20000) matrix\n",
      "I0703 12:55:30.282216 140392763574080 lsimodel.py:1013] computing the final decomposition\n",
      "I0703 12:55:30.284562 140392763574080 lsimodel.py:106] keeping 300 factors (discarding 11.908% of energy spectrum)\n",
      "I0703 12:55:57.592612 140392763574080 lsimodel.py:517] processed documents up to #20000\n",
      "I0703 12:55:57.736469 140392763574080 lsimodel.py:704] topic #0(15.685): 0.161*\"patients\" + 0.149*\"influenza\" + 0.122*\"virus\" + 0.115*\"cells\" + 0.114*\"infection\" + 0.102*\"cell\" + 0.101*\"viral\" + 0.095*\"disease\" + 0.091*\"viruses\" + 0.088*\"infections\"\n",
      "I0703 12:55:57.743271 140392763574080 lsimodel.py:704] topic #1(9.494): -0.293*\"patients\" + 0.233*\"cells\" + 0.176*\"cell\" + 0.153*\"virus\" + 0.135*\"protein\" + 0.118*\"proteins\" + 0.117*\"viral\" + 0.113*\"viruses\" + 0.111*\"host\" + 0.109*\"expression\"\n",
      "I0703 12:55:57.748235 140392763574080 lsimodel.py:704] topic #2(8.363): 0.236*\"health\" + -0.219*\"cells\" + -0.183*\"patients\" + 0.163*\"influenza\" + -0.156*\"lung\" + -0.148*\"cell\" + 0.140*\"public\" + -0.104*\"mice\" + -0.103*\"expression\" + -0.099*\"ards\"\n",
      "I0703 12:55:57.752061 140392763574080 lsimodel.py:704] topic #3(7.786): -0.656*\"influenza\" + -0.174*\"virus\" + -0.148*\"viruses\" + -0.137*\"respiratory\" + -0.116*\"avian\" + -0.112*\"children\" + -0.107*\"infection\" + -0.103*\"infections\" + -0.099*\"pneumonia\" + -0.094*\"pandemic\"\n",
      "I0703 12:55:57.756006 140392763574080 lsimodel.py:704] topic #4(7.024): -0.252*\"influenza\" + 0.242*\"lung\" + -0.162*\"laparoscopic\" + 0.152*\"ards\" + 0.150*\"diseases\" + 0.147*\"pulmonary\" + -0.139*\"group\" + -0.126*\"surgery\" + 0.125*\"respiratory\" + 0.115*\"health\"\n",
      "I0703 12:56:16.076338 140392763574080 lsimodel.py:492] preparing a new chunk of documents\n",
      "I0703 12:56:16.823391 140392763574080 lsimodel.py:912] using 100 extra samples and 2 power iterations\n",
      "I0703 12:56:16.824651 140392763574080 lsimodel.py:920] 1st phase: constructing (144354, 400) action matrix\n",
      "I0703 12:56:18.456522 140392763574080 lsimodel.py:935] orthonormalizing (144354, 400) action matrix\n",
      "I0703 12:56:40.832999 140392763574080 lsimodel.py:987] 2nd phase: running dense svd on (400, 20000) matrix\n",
      "I0703 12:56:43.115836 140392763574080 lsimodel.py:1013] computing the final decomposition\n",
      "I0703 12:56:43.117720 140392763574080 lsimodel.py:106] keeping 300 factors (discarding 10.799% of energy spectrum)\n",
      "I0703 12:57:09.858358 140392763574080 lsimodel.py:261] merging projections: (144354, 300) + (144354, 300)\n",
      "I0703 12:59:15.671000 140392763574080 lsimodel.py:106] keeping 300 factors (discarding 15.975% of energy spectrum)\n",
      "I0703 12:59:50.356483 140392763574080 lsimodel.py:517] processed documents up to #40000\n",
      "I0703 12:59:50.366926 140392763574080 lsimodel.py:704] topic #0(22.909): 0.247*\"patients\" + 0.117*\"group\" + 0.112*\"surgery\" + 0.110*\"laparoscopic\" + 0.097*\"treatment\" + 0.085*\"clinical\" + 0.085*\"complications\" + 0.082*\"risk\" + 0.078*\"outcomes\" + 0.078*\"influenza\"\n",
      "I0703 12:59:50.372436 140392763574080 lsimodel.py:704] topic #1(15.114): -0.247*\"laparoscopic\" + -0.188*\"surgery\" + -0.173*\"patients\" + 0.142*\"virus\" + -0.140*\"postoperative\" + 0.138*\"influenza\" + 0.126*\"cells\" + -0.122*\"group\" + 0.116*\"viral\" + -0.111*\"complications\"\n",
      "I0703 12:59:50.377418 140392763574080 lsimodel.py:704] topic #2(11.885): -0.256*\"laparoscopic\" + 0.192*\"stroke\" + -0.184*\"cells\" + -0.144*\"surgery\" + -0.141*\"cell\" + 0.136*\"patients\" + 0.128*\"care\" + 0.126*\"health\" + 0.122*\"covid\" + 0.116*\"aneurysms\"\n",
      "I0703 12:59:50.382262 140392763574080 lsimodel.py:704] topic #3(11.290): 0.222*\"health\" + -0.197*\"aneurysms\" + -0.190*\"stroke\" + 0.158*\"laparoscopic\" + -0.153*\"cells\" + -0.136*\"stent\" + -0.133*\"occlusion\" + -0.132*\"endovascular\" + 0.128*\"covid\" + -0.125*\"artery\"\n",
      "I0703 12:59:50.388232 140392763574080 lsimodel.py:704] topic #4(10.246): 0.243*\"patients\" + -0.209*\"aneurysms\" + 0.200*\"respiratory\" + 0.193*\"influenza\" + 0.148*\"children\" + -0.134*\"aneurysm\" + 0.134*\"pneumonia\" + 0.125*\"lung\" + 0.119*\"group\" + -0.117*\"health\"\n",
      "I0703 13:00:06.923490 140392763574080 lsimodel.py:492] preparing a new chunk of documents\n",
      "I0703 13:00:07.673644 140392763574080 lsimodel.py:912] using 100 extra samples and 2 power iterations\n",
      "I0703 13:00:07.674660 140392763574080 lsimodel.py:920] 1st phase: constructing (144354, 400) action matrix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 13:00:09.226670 140392763574080 lsimodel.py:935] orthonormalizing (144354, 400) action matrix\n",
      "I0703 13:00:32.284240 140392763574080 lsimodel.py:987] 2nd phase: running dense svd on (400, 20000) matrix\n",
      "I0703 13:00:34.706219 140392763574080 lsimodel.py:1013] computing the final decomposition\n",
      "I0703 13:00:34.707927 140392763574080 lsimodel.py:106] keeping 300 factors (discarding 10.954% of energy spectrum)\n",
      "I0703 13:01:01.998676 140392763574080 lsimodel.py:261] merging projections: (144354, 300) + (144354, 300)\n",
      "I0703 13:03:09.416321 140392763574080 lsimodel.py:106] keeping 300 factors (discarding 11.333% of energy spectrum)\n",
      "I0703 13:03:44.486397 140392763574080 lsimodel.py:517] processed documents up to #60000\n",
      "I0703 13:03:44.494930 140392763574080 lsimodel.py:704] topic #0(29.017): 0.233*\"patients\" + 0.162*\"covid\" + 0.144*\"sars\" + 0.097*\"group\" + 0.096*\"cases\" + 0.090*\"infection\" + 0.090*\"disease\" + 0.088*\"respiratory\" + 0.087*\"clinical\" + 0.087*\"health\"\n",
      "I0703 13:03:44.506030 140392763574080 lsimodel.py:704] topic #1(18.606): 0.228*\"laparoscopic\" + 0.215*\"patients\" + -0.210*\"sars\" + 0.190*\"surgery\" + -0.142*\"virus\" + 0.140*\"postoperative\" + 0.136*\"group\" + -0.117*\"cells\" + 0.116*\"complications\" + -0.108*\"protein\"\n",
      "I0703 13:03:44.512834 140392763574080 lsimodel.py:704] topic #2(15.612): 0.315*\"covid\" + -0.221*\"cells\" + 0.181*\"health\" + -0.175*\"protein\" + -0.163*\"cell\" + -0.135*\"virus\" + 0.118*\"care\" + 0.116*\"pandemic\" + -0.115*\"laparoscopic\" + -0.110*\"viral\"\n",
      "I0703 13:03:44.517286 140392763574080 lsimodel.py:704] topic #3(13.556): -0.279*\"laparoscopic\" + 0.253*\"patients\" + 0.225*\"stroke\" + -0.174*\"surgery\" + 0.146*\"aneurysms\" + -0.135*\"health\" + -0.126*\"port\" + 0.125*\"endovascular\" + 0.111*\"treatment\" + 0.110*\"occlusion\"\n",
      "I0703 13:03:44.521573 140392763574080 lsimodel.py:704] topic #4(13.129): 0.465*\"sars\" + 0.208*\"covid\" + 0.175*\"patients\" + -0.142*\"stroke\" + 0.140*\"respiratory\" + -0.131*\"health\" + 0.123*\"coronavirus\" + 0.121*\"cases\" + 0.120*\"laparoscopic\" + 0.119*\"severe\"\n",
      "I0703 13:04:00.171439 140392763574080 lsimodel.py:492] preparing a new chunk of documents\n",
      "I0703 13:04:00.918919 140392763574080 lsimodel.py:912] using 100 extra samples and 2 power iterations\n",
      "I0703 13:04:00.920473 140392763574080 lsimodel.py:920] 1st phase: constructing (144354, 400) action matrix\n",
      "I0703 13:04:02.386429 140392763574080 lsimodel.py:935] orthonormalizing (144354, 400) action matrix\n",
      "I0703 13:04:26.600081 140392763574080 lsimodel.py:987] 2nd phase: running dense svd on (400, 20000) matrix\n",
      "I0703 13:04:29.017822 140392763574080 lsimodel.py:1013] computing the final decomposition\n",
      "I0703 13:04:29.019716 140392763574080 lsimodel.py:106] keeping 300 factors (discarding 10.667% of energy spectrum)\n",
      "I0703 13:04:56.436521 140392763574080 lsimodel.py:261] merging projections: (144354, 300) + (144354, 300)\n",
      "I0703 13:07:02.506219 140392763574080 lsimodel.py:106] keeping 300 factors (discarding 9.199% of energy spectrum)\n",
      "I0703 13:07:36.900810 140392763574080 lsimodel.py:517] processed documents up to #80000\n",
      "I0703 13:07:36.912044 140392763574080 lsimodel.py:704] topic #0(34.837): 0.238*\"covid\" + 0.214*\"patients\" + 0.191*\"sars\" + 0.110*\"respiratory\" + 0.108*\"disease\" + 0.106*\"cases\" + 0.104*\"infection\" + 0.101*\"coronavirus\" + 0.099*\"health\" + 0.098*\"virus\"\n",
      "I0703 13:07:36.917798 140392763574080 lsimodel.py:704] topic #1(20.598): 0.274*\"patients\" + -0.248*\"sars\" + 0.166*\"laparoscopic\" + -0.162*\"virus\" + 0.155*\"surgery\" + -0.148*\"protein\" + -0.141*\"cells\" + 0.128*\"group\" + -0.125*\"viral\" + 0.110*\"postoperative\"\n",
      "I0703 13:07:36.922600 140392763574080 lsimodel.py:704] topic #2(18.975): 0.406*\"covid\" + 0.177*\"health\" + -0.163*\"cells\" + 0.151*\"pandemic\" + -0.138*\"protein\" + -0.126*\"laparoscopic\" + -0.124*\"cell\" + -0.108*\"group\" + -0.106*\"virus\" + 0.099*\"public\"\n",
      "I0703 13:07:36.927249 140392763574080 lsimodel.py:704] topic #3(16.342): 0.462*\"sars\" + 0.252*\"patients\" + -0.197*\"health\" + 0.161*\"respiratory\" + 0.156*\"covid\" + 0.148*\"severe\" + 0.124*\"coronavirus\" + -0.113*\"public\" + 0.112*\"syndrome\" + 0.112*\"acute\"\n",
      "I0703 13:07:36.931752 140392763574080 lsimodel.py:704] topic #4(14.977): -0.411*\"sars\" + 0.368*\"influenza\" + 0.241*\"children\" + 0.190*\"respiratory\" + 0.175*\"viruses\" + -0.162*\"laparoscopic\" + -0.144*\"protein\" + 0.144*\"infections\" + -0.139*\"covid\" + -0.122*\"surgery\"\n",
      "I0703 13:07:52.444904 140392763574080 lsimodel.py:492] preparing a new chunk of documents\n",
      "I0703 13:07:53.153610 140392763574080 lsimodel.py:912] using 100 extra samples and 2 power iterations\n",
      "I0703 13:07:53.154724 140392763574080 lsimodel.py:920] 1st phase: constructing (144354, 400) action matrix\n",
      "I0703 13:07:54.834004 140392763574080 lsimodel.py:935] orthonormalizing (144354, 400) action matrix\n",
      "I0703 13:08:20.324847 140392763574080 lsimodel.py:987] 2nd phase: running dense svd on (400, 20000) matrix\n",
      "I0703 13:08:22.558490 140392763574080 lsimodel.py:1013] computing the final decomposition\n",
      "I0703 13:08:22.561134 140392763574080 lsimodel.py:106] keeping 300 factors (discarding 10.439% of energy spectrum)\n",
      "I0703 13:08:49.746865 140392763574080 lsimodel.py:261] merging projections: (144354, 300) + (144354, 300)\n",
      "I0703 13:10:59.370209 140392763574080 lsimodel.py:106] keeping 300 factors (discarding 7.663% of energy spectrum)\n",
      "I0703 13:11:34.021901 140392763574080 lsimodel.py:517] processed documents up to #100000\n",
      "I0703 13:11:34.031553 140392763574080 lsimodel.py:704] topic #0(38.880): 0.207*\"covid\" + 0.195*\"sars\" + 0.188*\"patients\" + 0.129*\"respiratory\" + 0.120*\"virus\" + 0.114*\"infection\" + 0.107*\"disease\" + 0.102*\"coronavirus\" + 0.100*\"viral\" + 0.099*\"health\"\n",
      "I0703 13:11:34.036175 140392763574080 lsimodel.py:704] topic #1(23.097): 0.241*\"patients\" + 0.228*\"covid\" + -0.195*\"cells\" + -0.194*\"protein\" + -0.186*\"virus\" + -0.157*\"viral\" + -0.143*\"cell\" + -0.141*\"viruses\" + -0.129*\"sars\" + -0.125*\"proteins\"\n",
      "I0703 13:11:34.042610 140392763574080 lsimodel.py:704] topic #2(20.417): 0.305*\"covid\" + 0.256*\"sars\" + -0.197*\"patients\" + 0.186*\"health\" + -0.159*\"laparoscopic\" + -0.154*\"group\" + 0.144*\"pandemic\" + -0.136*\"surgery\" + 0.117*\"coronavirus\" + 0.113*\"public\"\n",
      "I0703 13:11:34.047719 140392763574080 lsimodel.py:704] topic #3(18.398): 0.470*\"sars\" + 0.220*\"respiratory\" + 0.197*\"patients\" + -0.196*\"health\" + 0.140*\"severe\" + 0.127*\"coronavirus\" + 0.120*\"children\" + 0.119*\"acute\" + 0.119*\"syndrome\" + -0.111*\"public\"\n",
      "I0703 13:11:34.052427 140392763574080 lsimodel.py:704] topic #4(18.068): 0.422*\"influenza\" + -0.357*\"sars\" + 0.241*\"children\" + 0.229*\"viruses\" + 0.207*\"respiratory\" + -0.169*\"covid\" + -0.164*\"protein\" + 0.160*\"infections\" + 0.127*\"virus\" + -0.123*\"cells\"\n",
      "I0703 13:11:37.034086 140392763574080 lsimodel.py:492] preparing a new chunk of documents\n",
      "I0703 13:11:37.153360 140392763574080 lsimodel.py:912] using 100 extra samples and 2 power iterations\n",
      "I0703 13:11:37.154690 140392763574080 lsimodel.py:920] 1st phase: constructing (144354, 400) action matrix\n",
      "I0703 13:11:37.516011 140392763574080 lsimodel.py:935] orthonormalizing (144354, 400) action matrix\n",
      "I0703 13:11:59.102862 140392763574080 lsimodel.py:987] 2nd phase: running dense svd on (400, 3482) matrix\n",
      "I0703 13:12:00.396383 140392763574080 lsimodel.py:1013] computing the final decomposition\n",
      "I0703 13:12:00.397801 140392763574080 lsimodel.py:106] keeping 300 factors (discarding 12.753% of energy spectrum)\n",
      "I0703 13:12:27.666310 140392763574080 lsimodel.py:261] merging projections: (144354, 300) + (144354, 300)\n",
      "I0703 13:14:39.383913 140392763574080 lsimodel.py:106] keeping 300 factors (discarding 2.642% of energy spectrum)\n",
      "I0703 13:15:13.968211 140392763574080 lsimodel.py:517] processed documents up to #103482\n",
      "I0703 13:15:13.977602 140392763574080 lsimodel.py:704] topic #0(39.578): 0.203*\"covid\" + 0.195*\"sars\" + 0.185*\"patients\" + 0.131*\"respiratory\" + 0.122*\"virus\" + 0.116*\"infection\" + 0.107*\"disease\" + 0.102*\"viral\" + 0.102*\"coronavirus\" + 0.100*\"influenza\"\n",
      "I0703 13:15:13.982180 140392763574080 lsimodel.py:704] topic #1(23.497): 0.240*\"covid\" + 0.237*\"patients\" + -0.197*\"cells\" + -0.194*\"protein\" + -0.186*\"virus\" + -0.157*\"viral\" + -0.144*\"cell\" + -0.143*\"viruses\" + -0.127*\"proteins\" + -0.117*\"sars\"\n",
      "I0703 13:15:13.987176 140392763574080 lsimodel.py:704] topic #2(20.634): 0.293*\"covid\" + 0.275*\"sars\" + -0.207*\"patients\" + 0.186*\"health\" + -0.155*\"group\" + -0.154*\"laparoscopic\" + 0.141*\"pandemic\" + -0.133*\"surgery\" + 0.120*\"coronavirus\" + 0.113*\"public\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 13:15:13.991231 140392763574080 lsimodel.py:704] topic #3(18.777): 0.448*\"sars\" + 0.237*\"respiratory\" + -0.191*\"health\" + 0.182*\"patients\" + 0.142*\"children\" + 0.136*\"severe\" + 0.123*\"coronavirus\" + 0.119*\"acute\" + 0.117*\"mers\" + 0.117*\"syndrome\"\n",
      "I0703 13:15:13.996148 140392763574080 lsimodel.py:704] topic #4(18.526): 0.419*\"influenza\" + -0.383*\"sars\" + 0.232*\"children\" + 0.230*\"viruses\" + 0.191*\"respiratory\" + -0.168*\"covid\" + -0.163*\"protein\" + 0.157*\"infections\" + 0.126*\"virus\" + -0.123*\"cells\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 1490.5347256660461 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "dictionary, lsi, corpus_lsi = tfidf_bow(doc_corpus)\n",
    "print('Time taken:', time.time()-start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save models and vectors for the corpus for TF-IDF\n",
    "with open('../models/tfidf_dict.pkl', 'wb') as f:\n",
    "    pickle.dump(dictionary,f)\n",
    "    \n",
    "with open('../models/tfidf_lsi.pkl', 'wb') as f:\n",
    "    pickle.dump(lsi,f)\n",
    "\n",
    "with open('../models/tfidf_vectors.pkl', 'wb') as f:\n",
    "    pickle.dump(corpus_lsi,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Word2Vec\"></a>\n",
    "### BERT with Cosine Distance \n",
    "<hr>\n",
    "Bidirectional Encoder Representations from Transformers (BERT) is a pre-trained model developed by Google. Unlike traditional RNNs or LSTMs, which only learn in one direction, BERT is trained in both directions and thus is better at understanding context. Once again we use Cosine distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T08:49:48.075947Z",
     "start_time": "2020-05-08T08:49:48.046956Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 13:15:30.404550 140392763574080 SentenceTransformer.py:29] Load pretrained SentenceTransformer: ../bin/models/\n",
      "I0703 13:15:30.406009 140392763574080 SentenceTransformer.py:67] Load SentenceTransformer from folder: ../bin/models/\n",
      "I0703 13:15:30.454168 140392763574080 configuration_utils.py:281] loading configuration file ../bin/models/0_BERT/config.json\n",
      "I0703 13:15:30.455682 140392763574080 configuration_utils.py:319] Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0703 13:15:30.457185 140392763574080 modeling_utils.py:505] loading weights file ../bin/models/0_BERT/pytorch_model.bin\n",
      "I0703 13:15:34.979927 140392763574080 tokenization_utils.py:417] Model name '../bin/models/0_BERT' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '../bin/models/0_BERT' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0703 13:15:34.983433 140392763574080 tokenization_utils.py:449] Didn't find file ../bin/models/0_BERT/tokenizer_config.json. We won't load it.\n",
      "I0703 13:15:34.984424 140392763574080 tokenization_utils.py:502] loading file ../bin/models/0_BERT/vocab.txt\n",
      "I0703 13:15:34.985128 140392763574080 tokenization_utils.py:502] loading file ../bin/models/0_BERT/added_tokens.json\n",
      "I0703 13:15:34.985812 140392763574080 tokenization_utils.py:502] loading file ../bin/models/0_BERT/special_tokens_map.json\n",
      "I0703 13:15:34.986472 140392763574080 tokenization_utils.py:502] loading file None\n",
      "I0703 13:15:35.036831 140392763574080 SentenceTransformer.py:88] Use pytorch device: cpu\n",
      "Batches: 100%|██████████| 12936/12936 [2:31:43<00:00,  1.42it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 9108.873574256897 seconds\n"
     ]
    }
   ],
   "source": [
    "# One time task (already done and stored embeddings in 'models') \n",
    "#To generate BERT Embeddings for CORD dataset and store the embeddings\n",
    "def make_bert_embeddings(doc_list):\n",
    "    generic_bert_model = SentenceTransformer('../bin/models/')\n",
    "    return generic_bert_model.encode(doc_list,show_progress_bar=True)\n",
    "\n",
    "start_time = time.time()\n",
    "# make the embeddings\n",
    "corpus_embed = make_bert_embeddings(list(doc_corpus))\n",
    "print('Time taken:', time.time()-start_time, 'seconds')\n",
    "\n",
    "with open('../models/bert_corpus_embed.pkl', 'wb') as f:\n",
    "    pickle.dump(corpus_embed, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"BERT-cos\"></a>\n",
    "### Pre-trained Word2vec using Word Centroid Similarity \n",
    "<hr>\n",
    "Word2vec is a NLP method for producing word embeddings using a neural network model such as a recurrent neural network (RNN). Word embeddings map words to vectors and thus can be used to represent words and thus documents/sentences. Here a pre-trained word2vec model on Google news is used. Once again we use Cosine distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centroid_matrix(EMBEDDING_FILE, vectorizer, tfidf_output):\n",
    "    w2v_model = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "\n",
    "    words = vectorizer.get_feature_names()\n",
    "\n",
    "    idx_present = []\n",
    "    for i, word in enumerate(words):\n",
    "        try:\n",
    "            vec = w2v_model[word]\n",
    "            idx_present.append(i)\n",
    "        except:\n",
    "            print(word)\n",
    "\n",
    "    vocab_words = [words[i] for i in range(len(words)) if i in idx_present]\n",
    "\n",
    "    term_occurrence_matrix = tfidf_output.toarray()\n",
    "    term_occurrence_matrix = term_occurrence_matrix[:,idx_present]\n",
    "\n",
    "    word_embeddings = w2v_model[vocab_words]\n",
    "\n",
    "    centroid_matrix = np.matmul(term_occurrence_matrix, word_embeddings)\n",
    "\n",
    "    return centroid_matrix, word_embeddings, idx_present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 16:10:05.175721 140392763574080 utils_any2vec.py:341] loading projection weights from ../bin/GoogleNews-vectors-negative300.bin.gz\n",
      "I0703 16:13:45.143670 140392763574080 utils_any2vec.py:405] loaded (3000000, 300) matrix from ../bin/GoogleNews-vectors-negative300.bin.gz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "analyses\n",
      "covid\n",
      "hcov\n",
      "mrna\n",
      "ncov\n",
      "pedv\n",
      "prrsv\n",
      "syncytial\n",
      "tgev\n",
      "wuhan\n",
      "Time taken: 974.4920225143433 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "EMBEDDING_FILE = '../bin/GoogleNews-vectors-negative300.bin.gz'\n",
    "centroid_matrix, word_embeddings, idx_present = get_centroid_matrix(EMBEDDING_FILE, vectorizer, tfidf_output)\n",
    "print('Time taken:', time.time()-start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save models and vectors for the corpus for word2vec\n",
    "with open('../models/centroid_vectors.pkl', 'wb') as f:\n",
    "    pickle.dump(centroid_matrix,f)\n",
    "    \n",
    "with open('../models/word_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(word_embeddings,f)\n",
    "\n",
    "with open('../models/common_vocab_idx.pkl', 'wb') as f:\n",
    "    pickle.dump(idx_present,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"Doc2vec\"></a>\n",
    "## Doc2vec with Cosine Distance \n",
    "<hr>\n",
    "Doc2vec is very similar to word2vec with a slight altercation that allows the model to consider which document a particular word comes from. The doc2vec model is trained on the dataset of medical abstracts, once again cosine distance is used to measure the similarity between documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_doc2vec(doc_list):\n",
    "\n",
    "    preprocess_list = []\n",
    "    for count, doc in enumerate(doc_list):\n",
    "        tokens = gensim.parsing.preprocess_string(doc)\n",
    "        preprocess_list.append(gensim.models.doc2vec.TaggedDocument(tokens, [count]))\n",
    "    return preprocess_list\n",
    "\n",
    "\n",
    "def train_doc2vec(train_corpus):\n",
    "    model = gensim.models.doc2vec.Doc2Vec(dm=1, vector_size=300, window=10, min_count=2, epochs=20, seed=42, workers=6)\n",
    "    model.build_vocab(train_corpus)\n",
    "    model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 16:29:29.675451 140392763574080 doc2vec.py:1377] collecting all words and their counts\n",
      "I0703 16:29:29.678025 140392763574080 doc2vec.py:1319] PROGRESS: at example #0, processed 0 words (0/s), 0 word types, 0 tags\n",
      "I0703 16:29:30.050217 140392763574080 doc2vec.py:1319] PROGRESS: at example #10000, processed 1184549 words (3189369/s), 42368 word types, 10000 tags\n",
      "I0703 16:29:30.399915 140392763574080 doc2vec.py:1319] PROGRESS: at example #20000, processed 2254253 words (3068558/s), 66679 word types, 20000 tags\n",
      "I0703 16:29:30.801015 140392763574080 doc2vec.py:1319] PROGRESS: at example #30000, processed 3514489 words (3150392/s), 76160 word types, 30000 tags\n",
      "I0703 16:29:31.200228 140392763574080 doc2vec.py:1319] PROGRESS: at example #40000, processed 4787273 words (3197073/s), 83759 word types, 40000 tags\n",
      "I0703 16:29:31.601248 140392763574080 doc2vec.py:1319] PROGRESS: at example #50000, processed 6047450 words (3150772/s), 91397 word types, 50000 tags\n",
      "I0703 16:29:31.955792 140392763574080 doc2vec.py:1319] PROGRESS: at example #60000, processed 7181687 words (3208990/s), 97922 word types, 60000 tags\n",
      "I0703 16:29:32.295192 140392763574080 doc2vec.py:1319] PROGRESS: at example #70000, processed 8246781 words (3148290/s), 105169 word types, 70000 tags\n",
      "I0703 16:29:32.653416 140392763574080 doc2vec.py:1319] PROGRESS: at example #80000, processed 9362073 words (3122845/s), 117939 word types, 80000 tags\n",
      "I0703 16:29:32.997572 140392763574080 doc2vec.py:1319] PROGRESS: at example #90000, processed 10454198 words (3183238/s), 127969 word types, 90000 tags\n",
      "I0703 16:29:33.320452 140392763574080 doc2vec.py:1319] PROGRESS: at example #100000, processed 11563408 words (3446749/s), 137089 word types, 100000 tags\n",
      "I0703 16:29:33.432243 140392763574080 doc2vec.py:1383] collected 140293 word types and 103482 unique tags from a corpus of 103482 examples and 11945646 words\n",
      "I0703 16:29:33.433286 140392763574080 word2vec.py:1647] Loading a fresh vocabulary\n",
      "I0703 16:29:33.665302 140392763574080 word2vec.py:1669] effective_min_count=2 retains 76749 unique words (54% of original 140293, drops 63544)\n",
      "I0703 16:29:33.666283 140392763574080 word2vec.py:1675] effective_min_count=2 leaves 11882102 word corpus (99% of original 11945646, drops 63544)\n",
      "I0703 16:29:34.112226 140392763574080 word2vec.py:1736] deleting the raw counts dictionary of 140293 items\n",
      "I0703 16:29:34.116179 140392763574080 word2vec.py:1739] sample=0.001 downsamples 33 most-common words\n",
      "I0703 16:29:34.117075 140392763574080 word2vec.py:1740] downsampling leaves estimated 11478420 word corpus (96.6% of prior 11882102)\n",
      "I0703 16:29:34.357105 140392763574080 base_any2vec.py:1020] estimated required memory for 76749 words and 300 dimensions: 346750500 bytes\n",
      "I0703 16:29:34.358084 140392763574080 word2vec.py:1888] resetting layer weights\n",
      "I0703 16:29:39.793546 140392763574080 base_any2vec.py:1206] training model with 6 workers on 76749 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "I0703 16:29:40.853388 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 4.10% examples, 505065 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:29:41.865640 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 9.08% examples, 530219 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:29:42.868039 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 14.10% examples, 504536 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:29:43.872480 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 18.65% examples, 515496 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:29:44.884932 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 22.80% examples, 515624 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:29:45.898354 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 27.11% examples, 520106 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:29:46.899224 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 31.28% examples, 521695 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:29:47.918253 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 35.58% examples, 524043 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:29:48.932105 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 39.81% examples, 525150 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:29:49.949776 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 44.08% examples, 526702 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:29:50.962202 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 48.39% examples, 526871 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:29:51.984459 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 52.75% examples, 524437 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:29:52.993991 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 57.35% examples, 522999 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:29:54.043124 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 61.80% examples, 518126 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:29:55.048038 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 66.58% examples, 517175 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:29:56.054610 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 70.82% examples, 513923 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:29:57.062887 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 75.16% examples, 511822 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:29:58.110222 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 79.62% examples, 509396 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:29:59.113222 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 83.86% examples, 506905 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:00.168908 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 88.56% examples, 506155 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:01.215921 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 93.26% examples, 505680 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:02.265249 140392763574080 base_any2vec.py:1302] EPOCH 1 - PROGRESS: at 97.93% examples, 505185 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:02.625992 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:30:02.633338 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:30:02.640537 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:30:02.650649 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:30:02.655497 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:30:02.674262 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:30:02.675103 140392763574080 base_any2vec.py:1344] EPOCH - 1 : training on 11945646 raw words (11577034 effective words) took 22.9s, 506127 effective words/s\n",
      "I0703 16:30:03.700048 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 4.10% examples, 522365 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:04.720219 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 8.69% examples, 506641 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:05.737817 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 13.41% examples, 484051 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:06.757318 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 17.96% examples, 493757 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:07.774272 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 22.27% examples, 501561 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:08.787303 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 26.66% examples, 510010 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:09.798100 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 30.91% examples, 513653 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:10.816833 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 35.12% examples, 515904 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:11.848987 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 39.51% examples, 518945 words/s, in_qsize 12, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 16:30:12.850034 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 43.71% examples, 521028 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:13.861137 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 48.01% examples, 521846 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:14.893269 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 52.41% examples, 520123 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:15.935516 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 57.08% examples, 518476 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:16.956444 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 61.80% examples, 516985 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:17.965720 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 66.23% examples, 513472 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:19.023603 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 70.91% examples, 511766 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:20.034440 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 75.51% examples, 511383 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:21.049078 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 79.80% examples, 508841 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:22.071383 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 84.38% examples, 507877 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:23.084514 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 88.82% examples, 506713 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:24.091329 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 93.52% examples, 507161 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:25.107003 140392763574080 base_any2vec.py:1302] EPOCH 2 - PROGRESS: at 98.01% examples, 506504 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:25.463617 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:30:25.468892 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:30:25.476081 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:30:25.502753 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:30:25.503978 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:30:25.504798 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:30:25.505547 140392763574080 base_any2vec.py:1344] EPOCH - 2 : training on 11945646 raw words (11576742 effective words) took 22.8s, 507247 effective words/s\n",
      "I0703 16:30:26.572374 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 4.10% examples, 502776 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:27.575333 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 8.69% examples, 501054 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:28.601990 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 13.11% examples, 469761 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:29.615412 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 17.66% examples, 481295 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:30.649687 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 21.88% examples, 487989 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:31.652429 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 26.29% examples, 499492 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:32.690900 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 30.38% examples, 499931 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:33.745632 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 34.90% examples, 506336 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:34.747176 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 39.20% examples, 511072 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:35.753080 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 43.41% examples, 513674 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:36.767403 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 47.87% examples, 516729 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:37.772566 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 52.15% examples, 515744 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:38.777429 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 56.58% examples, 513739 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:39.780932 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 61.16% examples, 512557 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:40.786000 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 65.68% examples, 510086 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:41.820602 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 70.21% examples, 508120 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:42.835145 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 74.65% examples, 506738 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:43.836554 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 79.10% examples, 505880 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:44.839993 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 83.69% examples, 505536 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:45.880643 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 88.13% examples, 503833 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:46.924660 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 92.83% examples, 503526 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:47.947764 140392763574080 base_any2vec.py:1302] EPOCH 3 - PROGRESS: at 97.33% examples, 502871 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:48.438575 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:30:48.445955 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:30:48.452654 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:30:48.473190 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:30:48.484440 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:30:48.498694 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:30:48.499674 140392763574080 base_any2vec.py:1344] EPOCH - 3 : training on 11945646 raw words (11576071 effective words) took 23.0s, 503658 effective words/s\n",
      "I0703 16:30:49.527042 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 4.10% examples, 521095 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:50.528005 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 8.53% examples, 501191 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:51.542712 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 13.10% examples, 477627 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:52.553255 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 17.59% examples, 485322 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:53.570645 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 21.88% examples, 494788 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:54.576816 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 25.98% examples, 498741 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:55.589429 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 30.16% examples, 502442 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:56.616811 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 34.45% examples, 506757 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:57.650752 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 38.73% examples, 509692 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:30:58.657947 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 43.04% examples, 513343 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:30:59.667601 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 47.32% examples, 515039 words/s, in_qsize 11, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 16:31:00.684846 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 51.71% examples, 515194 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:01.698748 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 56.23% examples, 513623 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:02.705533 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 60.79% examples, 512335 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:03.710139 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 65.32% examples, 509889 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:04.715250 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 69.85% examples, 508838 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:05.724549 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 74.30% examples, 507554 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:06.729360 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 78.74% examples, 506564 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:07.739471 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 83.06% examples, 504498 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:08.748946 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 87.64% examples, 504099 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:09.766226 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 92.21% examples, 503949 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:10.775393 140392763574080 base_any2vec.py:1302] EPOCH 4 - PROGRESS: at 96.71% examples, 503591 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:11.455547 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:31:11.463803 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:31:11.470738 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:31:11.497553 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:31:11.499902 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:31:11.503669 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:31:11.504502 140392763574080 base_any2vec.py:1344] EPOCH - 4 : training on 11945646 raw words (11576994 effective words) took 23.0s, 503407 effective words/s\n",
      "I0703 16:31:12.523135 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 4.03% examples, 516853 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:13.546787 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 8.61% examples, 502827 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:14.574105 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 13.12% examples, 473723 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:15.581090 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 17.66% examples, 485067 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:16.601497 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 21.88% examples, 492368 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:17.624665 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 26.06% examples, 496885 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:18.647415 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 30.39% examples, 502821 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:19.677952 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 34.68% examples, 506846 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:20.679408 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 38.73% examples, 508391 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:21.683798 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 43.04% examples, 512288 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:22.687884 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 47.32% examples, 514322 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:23.722201 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 51.71% examples, 513828 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:24.740464 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 56.32% examples, 512912 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:25.764628 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 60.88% examples, 511058 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:26.784102 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 65.41% examples, 508196 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:27.787958 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 69.85% examples, 506731 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:28.789618 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 74.30% examples, 505811 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:29.824656 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 78.84% examples, 504607 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:30.834372 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 83.23% examples, 503152 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:31.868816 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 87.64% examples, 501253 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:32.880148 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 92.12% examples, 500936 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:33.897694 140392763574080 base_any2vec.py:1302] EPOCH 5 - PROGRESS: at 96.45% examples, 499666 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:34.615056 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:31:34.622310 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:31:34.645555 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:31:34.650377 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:31:34.658256 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:31:34.659618 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:31:34.660290 140392763574080 base_any2vec.py:1344] EPOCH - 5 : training on 11945646 raw words (11576228 effective words) took 23.1s, 500125 effective words/s\n",
      "I0703 16:31:35.697276 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 4.10% examples, 517476 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:36.723726 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 8.61% examples, 497897 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:37.740963 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 13.10% examples, 472216 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:38.768597 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 17.59% examples, 479081 words/s, in_qsize 10, out_qsize 1\n",
      "I0703 16:31:39.779942 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 21.88% examples, 490302 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:40.788527 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 26.06% examples, 496299 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:41.796600 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 30.16% examples, 499331 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:42.802734 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 34.53% examples, 506479 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:43.840112 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 38.66% examples, 507168 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:44.841801 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 42.97% examples, 511305 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:45.858268 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 47.32% examples, 513749 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:46.878726 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 51.80% examples, 514639 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:47.929066 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 56.49% examples, 513160 words/s, in_qsize 12, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 16:31:48.980621 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 61.25% examples, 511646 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:49.981704 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 65.87% examples, 509984 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:51.020069 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 70.39% examples, 507937 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:52.042986 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 75.08% examples, 507986 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:53.056710 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 79.36% examples, 505687 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:54.075161 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 83.86% examples, 504477 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:55.102126 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 88.13% examples, 502218 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:56.117600 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 92.74% examples, 502216 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:31:57.138504 140392763574080 base_any2vec.py:1302] EPOCH 6 - PROGRESS: at 96.98% examples, 500378 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:57.744614 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:31:57.754651 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:31:57.772404 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:31:57.775536 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:31:57.789895 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:31:57.791620 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:31:57.792235 140392763574080 base_any2vec.py:1344] EPOCH - 6 : training on 11945646 raw words (11576964 effective words) took 23.1s, 500692 effective words/s\n",
      "I0703 16:31:58.842159 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 4.10% examples, 511855 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:31:59.867962 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 8.76% examples, 504686 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:00.905920 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 13.41% examples, 476723 words/s, in_qsize 10, out_qsize 1\n",
      "I0703 16:32:01.938325 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 17.81% examples, 481954 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:02.940329 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 22.19% examples, 495287 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:03.978658 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 26.36% examples, 498050 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:04.989179 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 30.61% examples, 503315 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:05.992105 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 34.90% examples, 508950 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:07.003417 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 39.04% examples, 510781 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:08.007981 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 43.26% examples, 513497 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:09.042087 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 47.79% examples, 516523 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:10.044085 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 52.15% examples, 516463 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:11.092194 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 56.83% examples, 514910 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:12.149618 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 61.62% examples, 513044 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:13.165452 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 66.41% examples, 512069 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:14.197424 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 70.82% examples, 509541 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:15.232109 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 75.51% examples, 509135 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:16.242805 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 80.14% examples, 508935 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:17.246725 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 84.47% examples, 506956 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:18.266426 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 89.09% examples, 506599 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:19.277593 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 93.44% examples, 505158 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:20.321773 140392763574080 base_any2vec.py:1302] EPOCH 7 - PROGRESS: at 98.01% examples, 504379 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:20.677966 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:32:20.691388 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:32:20.704922 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:32:20.713317 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:32:20.715073 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:32:20.716660 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:32:20.717354 140392763574080 base_any2vec.py:1344] EPOCH - 7 : training on 11945646 raw words (11576527 effective words) took 22.9s, 505227 effective words/s\n",
      "I0703 16:32:21.769536 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 4.10% examples, 508714 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:22.782686 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 8.69% examples, 501604 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:23.820361 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 13.52% examples, 480911 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:24.836851 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 17.88% examples, 486922 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:25.855361 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 22.11% examples, 493987 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:26.868019 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 26.37% examples, 500585 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:27.893317 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 30.76% examples, 507190 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:28.897424 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 34.90% examples, 509912 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:29.917094 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 39.12% examples, 512228 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:30.925649 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 43.26% examples, 513643 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:31.929565 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 47.64% examples, 516386 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:32.938989 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 51.88% examples, 515213 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:33.942068 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 56.41% examples, 514036 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:34.951078 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 60.88% examples, 511970 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:35.952633 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 65.50% examples, 510266 words/s, in_qsize 12, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 16:32:36.979693 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 69.75% examples, 506738 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:38.031572 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 74.47% examples, 506017 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:39.060507 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 79.18% examples, 506018 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:40.080228 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 83.86% examples, 505756 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:41.084450 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 88.30% examples, 504925 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:42.102885 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 92.83% examples, 504269 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:43.150170 140392763574080 base_any2vec.py:1302] EPOCH 8 - PROGRESS: at 97.51% examples, 503900 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:43.597960 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:32:43.600356 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:32:43.616375 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:32:43.629754 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:32:43.630711 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:32:43.631478 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:32:43.632194 140392763574080 base_any2vec.py:1344] EPOCH - 8 : training on 11945646 raw words (11576475 effective words) took 22.9s, 505364 effective words/s\n",
      "I0703 16:32:44.671795 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 4.10% examples, 515657 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:45.689811 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 8.61% examples, 499125 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:46.694872 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 13.11% examples, 474799 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:47.737689 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 17.58% examples, 479905 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:48.733250 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 21.96% examples, 493961 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:49.733299 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 26.22% examples, 501665 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:50.768107 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 30.67% examples, 508819 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:51.775063 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 34.90% examples, 512368 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:52.778357 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 39.20% examples, 516400 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:53.786450 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 43.41% examples, 518357 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:54.796666 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 47.87% examples, 521236 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:55.854958 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 52.33% examples, 519187 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:56.930040 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 56.99% examples, 516346 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:57.942596 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 61.61% examples, 514639 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:32:58.961491 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 66.14% examples, 511596 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:32:59.974992 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 70.82% examples, 511409 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:00.994368 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 75.24% examples, 509684 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:02.006818 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 79.88% examples, 509399 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:03.027336 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 84.20% examples, 506961 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:04.043506 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 88.82% examples, 506704 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:05.063428 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 93.52% examples, 506836 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:06.095469 140392763574080 base_any2vec.py:1302] EPOCH 9 - PROGRESS: at 97.77% examples, 504529 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:06.461735 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:33:06.470591 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:33:06.483598 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:33:06.513962 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:33:06.523538 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:33:06.526620 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:33:06.527626 140392763574080 base_any2vec.py:1344] EPOCH - 9 : training on 11945646 raw words (11576530 effective words) took 22.9s, 505826 effective words/s\n",
      "I0703 16:33:07.580762 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 4.10% examples, 508700 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:08.596863 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 8.61% examples, 496057 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:09.638628 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 13.41% examples, 476596 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:10.650294 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 17.96% examples, 489001 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:11.658351 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 22.27% examples, 498520 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:12.662803 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 26.51% examples, 505002 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:13.706461 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 30.75% examples, 506985 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:14.737017 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 35.05% examples, 510470 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:15.742149 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 39.35% examples, 514562 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:16.745994 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 43.34% examples, 514103 words/s, in_qsize 10, out_qsize 1\n",
      "I0703 16:33:17.747494 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 47.47% examples, 514368 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:18.757295 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 51.97% examples, 515684 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:19.776671 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 56.41% examples, 513157 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:20.776686 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 60.88% examples, 511486 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:21.777287 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 65.32% examples, 508605 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:22.787948 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 69.85% examples, 507469 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:23.795219 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 74.39% examples, 506895 words/s, in_qsize 12, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 16:33:24.816732 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 78.84% examples, 505482 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:25.887544 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 83.42% examples, 503400 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:26.910867 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 87.97% examples, 502691 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:27.916259 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 92.39% examples, 502011 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:28.924147 140392763574080 base_any2vec.py:1302] EPOCH 10 - PROGRESS: at 96.80% examples, 501333 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:29.585647 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:33:29.608578 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:33:29.615708 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:33:29.632746 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:33:29.635410 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:33:29.644058 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:33:29.644838 140392763574080 base_any2vec.py:1344] EPOCH - 10 : training on 11945646 raw words (11577031 effective words) took 23.1s, 500989 effective words/s\n",
      "I0703 16:33:30.670493 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 4.10% examples, 522309 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:31.677622 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 8.65% examples, 507208 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:32.692080 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 13.12% examples, 477088 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:33.696854 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 17.51% examples, 483122 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:34.706275 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 21.73% examples, 491884 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:35.760737 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 25.91% examples, 493983 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:36.766871 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 30.00% examples, 497457 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:37.781301 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 34.45% examples, 505552 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:38.786175 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 38.58% examples, 508142 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:39.791809 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 42.97% examples, 512962 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:40.809897 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 47.17% examples, 513450 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:41.821021 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 51.71% examples, 515570 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:42.831953 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 56.32% examples, 514802 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:43.865318 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 60.79% examples, 511793 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:44.891528 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 65.50% examples, 509905 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:45.899679 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 69.85% examples, 507587 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:46.924979 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 74.39% examples, 506455 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:47.963779 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 78.83% examples, 504593 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:48.979653 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 83.32% examples, 503479 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:49.998109 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 87.64% examples, 501487 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:51.009256 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 92.12% examples, 501168 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:52.028077 140392763574080 base_any2vec.py:1302] EPOCH 11 - PROGRESS: at 96.61% examples, 500721 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:52.715226 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:33:52.719434 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:33:52.736899 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:33:52.762120 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:33:52.766285 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:33:52.767198 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:33:52.768063 140392763574080 base_any2vec.py:1344] EPOCH - 11 : training on 11945646 raw words (11576110 effective words) took 23.1s, 500809 effective words/s\n",
      "I0703 16:33:53.822132 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 4.10% examples, 510370 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:54.839295 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 8.69% examples, 501479 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:55.865227 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 13.12% examples, 470125 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:56.879420 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 17.59% examples, 479099 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:57.902801 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 21.88% examples, 489135 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:33:58.910175 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 26.06% examples, 495435 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:33:59.944396 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 30.31% examples, 499430 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:00.970437 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 34.68% examples, 505347 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:02.008548 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 39.04% examples, 509221 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:03.032476 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 43.41% examples, 512995 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:04.032336 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 47.79% examples, 515949 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:05.062033 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 52.15% examples, 514778 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:06.073027 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 56.66% examples, 513341 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:07.080956 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 61.25% examples, 512034 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:08.097831 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 65.77% examples, 509223 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:09.103353 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 70.30% examples, 508225 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:10.114177 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 74.74% examples, 506950 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:11.183650 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 79.36% examples, 505255 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:12.234695 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 84.12% examples, 504716 words/s, in_qsize 12, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 16:34:13.264767 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 88.82% examples, 504692 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:14.281805 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 93.36% examples, 504105 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:15.287469 140392763574080 base_any2vec.py:1302] EPOCH 12 - PROGRESS: at 97.77% examples, 503376 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:15.695731 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:34:15.718234 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:34:15.733360 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:34:15.748628 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:34:15.759448 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:34:15.765062 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:34:15.765819 140392763574080 base_any2vec.py:1344] EPOCH - 12 : training on 11945646 raw words (11576911 effective words) took 23.0s, 503680 effective words/s\n",
      "I0703 16:34:16.815025 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 4.10% examples, 511291 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:17.822617 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 8.69% examples, 504172 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:18.848265 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 13.41% examples, 481314 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:19.856908 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 18.04% examples, 495320 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:20.859969 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 22.27% examples, 502294 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:21.867306 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 26.44% examples, 506341 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:22.876522 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 30.53% examples, 507892 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:23.884397 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 34.76% examples, 511550 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:24.888990 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 39.04% examples, 515573 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:25.898053 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 43.26% examples, 517602 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:26.924297 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 47.56% examples, 518123 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:27.931098 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 51.97% examples, 518485 words/s, in_qsize 10, out_qsize 1\n",
      "I0703 16:34:28.969079 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 56.49% examples, 515721 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:29.971847 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 61.16% examples, 515081 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:30.997577 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 65.77% examples, 512370 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:32.018546 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 70.30% examples, 510696 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:33.037195 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 74.82% examples, 509608 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:34.053150 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 79.36% examples, 508707 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:35.060940 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 83.86% examples, 507604 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:36.063264 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 88.22% examples, 506263 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:37.065450 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 92.66% examples, 505490 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:38.081404 140392763574080 base_any2vec.py:1302] EPOCH 13 - PROGRESS: at 97.15% examples, 504901 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:38.648986 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:34:38.652845 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:34:38.687556 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:34:38.701949 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:34:38.704489 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:34:38.706429 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:34:38.707416 140392763574080 base_any2vec.py:1344] EPOCH - 13 : training on 11945646 raw words (11577493 effective words) took 22.9s, 504855 effective words/s\n",
      "I0703 16:34:39.757713 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 4.10% examples, 510031 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:40.770484 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 8.80% examples, 509172 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:41.793835 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 13.52% examples, 483666 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:42.829973 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 18.04% examples, 491348 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:43.850422 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 22.35% examples, 499253 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:44.876795 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 26.74% examples, 506931 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:45.908419 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 30.91% examples, 508176 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:46.917671 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 35.34% examples, 515161 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:47.924238 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 39.58% examples, 517609 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:48.938702 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 43.86% examples, 520064 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:49.952155 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 48.32% examples, 522503 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:50.996285 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 52.75% examples, 520299 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:52.054070 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 57.44% examples, 518044 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:53.068924 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 62.07% examples, 516109 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:54.108845 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 66.58% examples, 512274 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:55.117048 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 71.08% examples, 511064 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:56.119331 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 75.51% examples, 509868 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:57.141576 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 80.05% examples, 508780 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:34:58.167174 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 84.38% examples, 506253 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:34:59.201148 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 89.00% examples, 505589 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:00.201446 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 93.35% examples, 504462 words/s, in_qsize 11, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 16:35:01.222326 140392763574080 base_any2vec.py:1302] EPOCH 14 - PROGRESS: at 97.77% examples, 503383 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:01.655866 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:35:01.664977 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:35:01.674319 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:35:01.692187 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:35:01.706180 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:35:01.709486 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:35:01.710280 140392763574080 base_any2vec.py:1344] EPOCH - 14 : training on 11945646 raw words (11577264 effective words) took 23.0s, 503473 effective words/s\n",
      "I0703 16:35:02.738271 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 4.10% examples, 520649 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:03.744883 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 8.61% examples, 504410 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:04.793639 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 13.41% examples, 480807 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:05.794824 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 17.81% examples, 488766 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:06.807820 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 22.04% examples, 495999 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:07.807968 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 26.14% examples, 500157 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:08.813286 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 30.39% examples, 505536 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:09.854656 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 34.68% examples, 508582 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:10.859933 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 38.88% examples, 511853 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:11.894607 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 43.26% examples, 514844 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:12.917269 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 47.56% examples, 515777 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:13.918974 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 51.88% examples, 515729 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:14.945764 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 56.50% examples, 514355 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:15.950899 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 60.97% examples, 512373 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:16.972401 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 65.41% examples, 508761 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:18.021870 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 69.75% examples, 505227 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:19.024664 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 74.30% examples, 504907 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:20.035879 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 78.65% examples, 503352 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:21.057776 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 82.96% examples, 501156 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:22.090825 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 87.55% examples, 500350 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:23.135570 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 92.21% examples, 500188 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:24.179062 140392763574080 base_any2vec.py:1302] EPOCH 15 - PROGRESS: at 96.89% examples, 500089 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:24.778944 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:35:24.782245 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:35:24.787594 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:35:24.811903 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:35:24.816280 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:35:24.825515 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:35:24.826241 140392763574080 base_any2vec.py:1344] EPOCH - 15 : training on 11945646 raw words (11576610 effective words) took 23.1s, 500966 effective words/s\n",
      "I0703 16:35:25.879550 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 4.10% examples, 509550 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:26.898287 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 8.69% examples, 500707 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:27.930945 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 13.41% examples, 477957 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:28.952007 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 17.81% examples, 484190 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:29.970802 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 22.11% examples, 493601 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:31.000784 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 26.29% examples, 497291 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:32.024422 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 30.61% examples, 503107 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:33.033494 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 34.83% examples, 507199 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:34.041610 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 39.04% examples, 510457 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:35.061115 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 43.33% examples, 513380 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:36.069227 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 47.64% examples, 515076 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:37.073622 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 52.06% examples, 515816 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:38.092334 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 56.50% examples, 513298 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:39.113423 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 61.07% examples, 511506 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:40.137593 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 65.77% examples, 509730 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:41.140492 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 70.30% examples, 508783 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:42.152016 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 74.74% examples, 507465 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:43.152371 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 79.18% examples, 506586 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:44.161800 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 83.86% examples, 506554 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:45.174352 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 88.39% examples, 505957 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:46.201378 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 92.74% examples, 504215 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:47.228957 140392763574080 base_any2vec.py:1302] EPOCH 16 - PROGRESS: at 97.33% examples, 503789 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:47.774222 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 16:35:47.776496 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:35:47.778551 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:35:47.794995 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:35:47.813030 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:35:47.824632 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:35:47.825597 140392763574080 base_any2vec.py:1344] EPOCH - 16 : training on 11945646 raw words (11576662 effective words) took 23.0s, 503579 effective words/s\n",
      "I0703 16:35:48.850425 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 4.10% examples, 523279 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:49.854895 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 8.69% examples, 511183 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:50.870074 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 13.41% examples, 487257 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:51.882165 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 17.73% examples, 489981 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:52.895952 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 21.88% examples, 495074 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:53.905114 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 25.91% examples, 497106 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:35:54.944803 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 30.16% examples, 500512 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:55.962677 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 34.37% examples, 504440 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:56.970856 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 38.58% examples, 508008 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:35:57.993046 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 42.66% examples, 508230 words/s, in_qsize 12, out_qsize 1\n",
      "I0703 16:35:58.995867 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 47.01% examples, 511589 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:00.009568 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 51.19% examples, 510582 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:01.040493 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 55.70% examples, 508729 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:02.047392 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 60.06% examples, 506477 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:03.069875 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 64.68% examples, 504461 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:04.087285 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 69.35% examples, 503532 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:05.116850 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 73.60% examples, 501216 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:06.152506 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 78.04% examples, 499739 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:07.161602 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 82.70% examples, 500074 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:08.175753 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 87.02% examples, 498360 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:09.233917 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 91.68% examples, 497985 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:10.240667 140392763574080 base_any2vec.py:1302] EPOCH 17 - PROGRESS: at 96.20% examples, 497973 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:11.029019 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:36:11.042000 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:36:11.053449 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:36:11.070044 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:36:11.072351 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:36:11.073620 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:36:11.074417 140392763574080 base_any2vec.py:1344] EPOCH - 17 : training on 11945646 raw words (11578066 effective words) took 23.2s, 498203 effective words/s\n",
      "I0703 16:36:12.114980 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 4.10% examples, 514854 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:13.121211 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 8.53% examples, 496862 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:14.152381 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 13.10% examples, 472339 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:15.166289 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 17.51% examples, 478508 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:16.197741 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 21.88% examples, 489839 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:17.200661 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 25.91% examples, 493234 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:18.210617 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 30.08% examples, 497877 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:19.213441 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 34.37% examples, 504242 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:20.238675 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 38.58% examples, 506906 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:21.293991 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 42.97% examples, 509337 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:22.294322 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 47.31% examples, 512706 words/s, in_qsize 10, out_qsize 1\n",
      "I0703 16:36:23.309784 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 51.71% examples, 513120 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:24.317821 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 56.06% examples, 510467 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:25.329520 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 60.61% examples, 509248 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:26.334514 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 65.04% examples, 506360 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:27.334987 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 69.66% examples, 506247 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:28.368921 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 73.95% examples, 503283 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:29.398687 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 78.40% examples, 501840 words/s, in_qsize 10, out_qsize 1\n",
      "I0703 16:36:30.401160 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 82.88% examples, 501235 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:31.410514 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 87.37% examples, 500524 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:32.413912 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 91.68% examples, 499513 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:33.425895 140392763574080 base_any2vec.py:1302] EPOCH 18 - PROGRESS: at 96.20% examples, 499306 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:34.174110 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:36:34.180689 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:36:34.181867 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 16:36:34.216783 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:36:34.222323 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:36:34.230087 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:36:34.230824 140392763574080 base_any2vec.py:1344] EPOCH - 18 : training on 11945646 raw words (11576480 effective words) took 23.1s, 500110 effective words/s\n",
      "I0703 16:36:35.244275 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 4.17% examples, 537736 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:36.260840 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 8.76% examples, 514923 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:37.263648 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 13.31% examples, 485527 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:38.273782 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 17.66% examples, 488890 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:39.280514 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 21.96% examples, 498750 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:40.291276 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 26.22% examples, 504812 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:41.292079 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 30.46% examples, 509928 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:42.292385 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 34.68% examples, 513814 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:43.317712 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 38.88% examples, 515395 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:44.323574 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 43.26% examples, 519508 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:45.369272 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 47.47% examples, 518084 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:46.382931 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 51.80% examples, 517347 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:47.393788 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 56.50% examples, 517186 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:48.461326 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 61.16% examples, 514108 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:49.476764 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 65.96% examples, 513081 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:50.489004 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 70.30% examples, 510448 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:51.532600 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 74.91% examples, 509197 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:52.538321 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 79.27% examples, 507540 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:53.574415 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 83.77% examples, 505765 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:54.582973 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 88.05% examples, 503876 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:55.591804 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 92.57% examples, 503507 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:56.621442 140392763574080 base_any2vec.py:1302] EPOCH 19 - PROGRESS: at 96.89% examples, 501845 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:36:57.222044 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:36:57.224635 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:36:57.256683 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:36:57.263408 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:36:57.268736 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n",
      "I0703 16:36:57.279318 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:36:57.280261 140392763574080 base_any2vec.py:1344] EPOCH - 19 : training on 11945646 raw words (11576652 effective words) took 23.0s, 502413 effective words/s\n",
      "I0703 16:36:58.333125 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 4.10% examples, 509504 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:36:59.359273 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 8.61% examples, 494085 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:37:00.372430 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 13.11% examples, 470336 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:37:01.379015 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 17.66% examples, 482492 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:37:02.390112 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 21.96% examples, 493079 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:37:03.415178 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 26.29% examples, 500443 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:37:04.430024 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 30.60% examples, 506457 words/s, in_qsize 11, out_qsize 1\n",
      "I0703 16:37:05.461273 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 34.90% examples, 509965 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:37:06.462850 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 39.04% examples, 512230 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:37:07.480235 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 43.33% examples, 515094 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:37:08.492471 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 47.56% examples, 515618 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:37:09.497911 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 51.88% examples, 515467 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:37:10.514971 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 56.50% examples, 514490 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:37:11.553490 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 61.06% examples, 511995 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:37:12.555695 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 65.77% examples, 510926 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:37:13.573608 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 70.30% examples, 509430 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:37:14.579607 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 74.65% examples, 507670 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:37:15.584980 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 79.18% examples, 507178 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:37:16.613970 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 83.60% examples, 505093 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:37:17.617921 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 88.13% examples, 504785 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:37:18.637365 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 92.57% examples, 503661 words/s, in_qsize 12, out_qsize 0\n",
      "I0703 16:37:19.642392 140392763574080 base_any2vec.py:1302] EPOCH 20 - PROGRESS: at 97.15% examples, 503827 words/s, in_qsize 11, out_qsize 0\n",
      "I0703 16:37:20.184979 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 5 more threads\n",
      "I0703 16:37:20.208659 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 4 more threads\n",
      "I0703 16:37:20.219268 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 3 more threads\n",
      "I0703 16:37:20.250032 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 2 more threads\n",
      "I0703 16:37:20.252445 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 1 more threads\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0703 16:37:20.253400 140392763574080 base_any2vec.py:349] worker thread finished; awaiting finish of 0 more threads\n",
      "I0703 16:37:20.254100 140392763574080 base_any2vec.py:1344] EPOCH - 20 : training on 11945646 raw words (11576751 effective words) took 23.0s, 504126 effective words/s\n",
      "I0703 16:37:20.255048 140392763574080 base_any2vec.py:1380] training on a 238912920 raw words (231535595 effective words) took 460.5s, 502835 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "658.0700414180756 seconds\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "preprocess_list = preprocess_doc2vec(doc_corpus)\n",
    "doc2vec_model = train_doc2vec(preprocess_list)\n",
    "print(time.time()-start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "docvecs = doc2vec_model.docvecs\n",
    "\n",
    "#Save models and vectors for the corpus for word2vec\n",
    "with open('../models/d2v_model.pkl', 'wb') as f:\n",
    "    pickle.dump(doc2vec_model,f)\n",
    "    \n",
    "with open('../models/d2v_vectors.pkl', 'wb') as f:\n",
    "    pickle.dump(docvecs,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"SciBert-cos\"></a>\n",
    "## SciBERT with Cosine distance\n",
    "<hr>\n",
    "SciBERT (https://github.com/allenai/scibert) is a BERT model that is specifically pre-trained on medical journal articles. Therefore the model is potentially more suitable for analyzing coronavirus related material than a typical pre-trained BERT model. Cosine distance is also used with the SciBERT model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0705 08:31:14.933726 139995567662912 configuration_utils.py:281] loading configuration file ../bin/models/scibert_scivocab_uncased/config.json\n",
      "I0705 08:31:14.935277 139995567662912 configuration_utils.py:319] Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "I0705 08:31:14.936765 139995567662912 modeling_utils.py:505] loading weights file ../bin/models/scibert_scivocab_uncased/pytorch_model.bin\n",
      "I0705 08:31:19.893694 139995567662912 configuration_utils.py:281] loading configuration file ../bin/models/scibert_scivocab_uncased/config.json\n",
      "I0705 08:31:19.896134 139995567662912 configuration_utils.py:319] Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "I0705 08:31:19.897213 139995567662912 tokenization_utils.py:417] Model name '../bin/models/scibert_scivocab_uncased/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '../bin/models/scibert_scivocab_uncased/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0705 08:31:19.898810 139995567662912 tokenization_utils.py:449] Didn't find file ../bin/models/scibert_scivocab_uncased/added_tokens.json. We won't load it.\n",
      "I0705 08:31:19.899672 139995567662912 tokenization_utils.py:449] Didn't find file ../bin/models/scibert_scivocab_uncased/special_tokens_map.json. We won't load it.\n",
      "I0705 08:31:19.900510 139995567662912 tokenization_utils.py:449] Didn't find file ../bin/models/scibert_scivocab_uncased/tokenizer_config.json. We won't load it.\n",
      "I0705 08:31:19.901337 139995567662912 tokenization_utils.py:502] loading file ../bin/models/scibert_scivocab_uncased/vocab.txt\n",
      "I0705 08:31:19.901988 139995567662912 tokenization_utils.py:502] loading file None\n",
      "I0705 08:31:19.902738 139995567662912 tokenization_utils.py:502] loading file None\n",
      "I0705 08:31:19.903455 139995567662912 tokenization_utils.py:502] loading file None\n"
     ]
    }
   ],
   "source": [
    "model = BertModel.from_pretrained(\"../bin/models/scibert_scivocab_uncased/\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../bin/models/scibert_scivocab_uncased/\")\n",
    "device = torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "def get_scibert_embedding(doc,model,tokenizer,device):\n",
    "\n",
    "    # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "    input_ids = torch.tensor([tokenizer.encode(doc,add_special_tokens=True, max_length=512)],device=device)\n",
    "    try:\n",
    "        with torch.no_grad():\n",
    "            last_hidden_states = model(input_ids)  # Models outputs are now tuples\n",
    "            test = last_hidden_states[0].mean(1).detach()\n",
    "        return np.array(test.cpu())\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(f'Was not able to get embeddings for {doc}')\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4c177dc4a7a47b09be939b634b65451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=103482.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "26110.16163277626\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "abstract_embedd_list = []\n",
    "for index_f in tqdm(list(doc_corpus)):\n",
    "    embed_vals = get_scibert_embedding(index_f,model,tokenizer,device)\n",
    "\n",
    "    if len(embed_vals)>0:\n",
    "        abstract_embedd_list.append(embed_vals)\n",
    "print(time.time()-start_time)\n",
    "\n",
    "with open('../models/scibert_corpus_embed.pkl', 'wb') as f:\n",
    "    pickle.dump(abstract_embedd_list, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:15:25.910299Z",
     "start_time": "2020-05-08T14:15:25.906298Z"
    }
   },
   "source": [
    "# Phase II - Indexing, Searching and Summarization\n",
    "<hr> \n",
    "<b>Query based recurring tasks</b> <br>\n",
    "Once Phase I completes, we index the vectors and documents in Elasticsearch and perform our user searches on the given index. There are 5 stages in this phase - <br>\n",
    "1. Data/Embedding Ingestion into Elasticsearch as dense vectors <br>\n",
    "2. Generation of embeddings for user search input <br>\n",
    "3. Matching (user input embeddings and document vectors) using Dense Vector API and score using cosine similarity <br>\n",
    "4. Summarizing the relevant retrieved documents using BERT summarizer <br>\n",
    "5. Displaying search results in the Flask search UI <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and Searching in Elasticsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Indexing data in ES\n",
    "def index_data():\n",
    "    print(\"Creating the index.\")\n",
    "    client.indices.delete(index=INDEX_NAME, ignore=[404])\n",
    "\n",
    "    with open(INDEX_FILE) as index_file:\n",
    "        source = index_file.read().strip()\n",
    "        client.indices.create(index=INDEX_NAME, body=source)\n",
    "\n",
    "    docs = []\n",
    "    count = 0\n",
    "\n",
    "    with open(DATA_FILE) as data_file:\n",
    "        for line in data_file:\n",
    "            line = line.strip()\n",
    "\n",
    "            try:\n",
    "                doc = json.loads(line)\n",
    "            except:\n",
    "                print(count, \"Could not load doc:\", line)\n",
    "                continue\n",
    "        \n",
    "            docs.append(doc)\n",
    "            count += 1\n",
    "\n",
    "            if count % BATCH_SIZE == 0:\n",
    "                index_batch(docs,count)\n",
    "                docs = []\n",
    "                print(\"Indexed {} documents.\".format(count))\n",
    "\n",
    "        if docs:\n",
    "            index_batch(docs,count)\n",
    "            print(\"Indexed {} documents.\".format(count))\n",
    "\n",
    "    client.indices.refresh(index=INDEX_NAME)\n",
    "    print(\"Done indexing.\")\n",
    "\n",
    "def index_batch(docs,count):\n",
    "    requests = []\n",
    "    for i, doc in enumerate(docs):\n",
    "        request = doc\n",
    "        request[\"_op_type\"] = \"index\"\n",
    "        request[\"_index\"] = INDEX_NAME\n",
    "        request[\"tm_doc_vec\"] = tm_doc_embed(i+count-BATCH_SIZE)\n",
    "        request[\"tfidf_doc_vec\"] = tfidf_doc_embed(i+count-BATCH_SIZE)\n",
    "        request[\"bert_doc_vec\"] = bert_doc_embed(i+count-BATCH_SIZE)\n",
    "        request[\"w2v_doc_vec\"] = w2v_doc_embed(i+count-BATCH_SIZE)\n",
    "        request[\"scibert_doc_vec\"] = scibert_doc_embed(i+count-BATCH_SIZE)\n",
    "        request[\"d2v_doc_vec\"] = d2v_doc_embed(i+count-BATCH_SIZE)\n",
    "        requests.append(request)\n",
    "    bulk(client, requests)\n",
    "\n",
    "\"\"\"Intermediate func (not used independently anymore)\n",
    "Created to test the code from within notebook and now, the same functionality is implemented in flask code\"\"\" \n",
    "\n",
    "def handle_query():\n",
    "    query = input(\"Enter query: \")\n",
    "\n",
    "    embedding_start = time.time()\n",
    "    tm_query_vec = tm_query_embed(query)\n",
    "    tfidf_query_vec = tfidf_query_embed(query)\n",
    "    bert_query_vec = bert_query_embed(query)\n",
    "    w2v_query_vec = w2v_query_embed(query)\n",
    "    embedding_time = time.time() - embedding_start\n",
    "\n",
    "    script_query = {\n",
    "        \"script_score\": {\n",
    "            \"query\": {\"match_all\": {}},\n",
    "            \"script\": {\n",
    "                \"source\": \"cosineSimilarity(params.w2v_qv, doc['w2v_doc_vec']) + cosineSimilarity(params.tm_qv, doc['tm_doc_vec']) + cosineSimilarity(params.tfidf_qv, doc['tfidf_doc_vec']) + cosineSimilarity(params.bert_qv, doc['bert_doc_vec']) + 4.0\",\n",
    "                \"params\": {\"w2v_qv\": w2v_query_vec, \"tm_qv\": tm_query_vec, \"tfidf_qv\": tfidf_query_vec, \"bert_qv\": bert_query_vec}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    search_start = time.time()\n",
    "    response = client.search(\n",
    "        index=INDEX_NAME,\n",
    "        body={\n",
    "            \"size\": SEARCH_SIZE,\n",
    "            \"query\": script_query,\n",
    "            \"_source\": {\"includes\": [\"title\", \"abstract\", \"url\", \"authors\"]}\n",
    "        }\n",
    "    )\n",
    "    search_time = time.time() - search_start\n",
    "\n",
    "    print()\n",
    "    print(\"{} total hits.\".format(response[\"hits\"][\"total\"][\"value\"]))\n",
    "    print(\"embedding time: {:.2f} ms\".format(embedding_time * 1000))\n",
    "    print(\"search time: {:.2f} ms\".format(search_time * 1000))\n",
    "    for hit in response[\"hits\"][\"hits\"]:\n",
    "        print(\"id: {}, score: {}\".format(hit[\"_id\"], hit[\"_score\"]))\n",
    "        print(hit[\"_source\"])\n",
    "        print()\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Wrapper to run ingestion to ES\n",
    "def run_query_loop():\n",
    "    while True:\n",
    "        try:\n",
    "            handle_query()\n",
    "        except KeyboardInterrupt:\n",
    "            return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding functions for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tm_doc_embed(idx):\n",
    "    doc_vec = tm_output[idx,]\n",
    "    if(sum(doc_vec)==0): #to avoid all zeros (cosine similarity)\n",
    "        doc_vec = doc_vec + 1e-6\n",
    "    return doc_vec.tolist()\n",
    "\n",
    "def tm_query_embed(query):\n",
    "    clean_query = clean_docs([query])\n",
    "    tfidf_query_output = vectorizer.transform(clean_query)\n",
    "    target_vec = svd_model.transform(tfidf_query_output)[0]\n",
    "    if(sum(target_vec)==0): #to avoid all zeros (cosine similarity)\n",
    "        target_vec = target_vec + 1e-6\n",
    "    return target_vec.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_doc_embed(idx):\n",
    "    doc_vec = [item[1] for item in corpus_lsi[idx]]\n",
    "    if len(doc_vec)!=300: #to ensure size of vectors is 300\n",
    "        doc_vec.extend((300-len(doc_vec))*[1e-6])\n",
    "    return doc_vec\n",
    "\n",
    "def tfidf_query_embed(query):\n",
    "    detokenized_compare_doc = clean_docs([query])\n",
    "    gen_compare_docs = [[w.lower() for w in word_tokenize(text)] for text in detokenized_compare_doc]\n",
    "    query_doc_bow = dictionary.doc2bow(gen_compare_docs[0])\n",
    "    query_lsi = lsi[query_doc_bow]\n",
    "    query_vec_tfidf = [item[1] for item in query_lsi]\n",
    "    return query_vec_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-05-08T12:04:26.467Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0707 15:00:59.041806 140149010638656 SentenceTransformer.py:29] Load pretrained SentenceTransformer: ../bin/models/\n",
      "I0707 15:00:59.043388 140149010638656 SentenceTransformer.py:67] Load SentenceTransformer from folder: ../bin/models/\n",
      "I0707 15:00:59.078465 140149010638656 configuration_utils.py:281] loading configuration file ../bin/models/0_BERT/config.json\n",
      "I0707 15:00:59.079786 140149010638656 configuration_utils.py:319] Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0707 15:00:59.081044 140149010638656 modeling_utils.py:505] loading weights file ../bin/models/0_BERT/pytorch_model.bin\n",
      "I0707 15:01:03.384325 140149010638656 tokenization_utils.py:417] Model name '../bin/models/0_BERT' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '../bin/models/0_BERT' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0707 15:01:03.386986 140149010638656 tokenization_utils.py:449] Didn't find file ../bin/models/0_BERT/tokenizer_config.json. We won't load it.\n",
      "I0707 15:01:03.387939 140149010638656 tokenization_utils.py:502] loading file ../bin/models/0_BERT/vocab.txt\n",
      "I0707 15:01:03.388664 140149010638656 tokenization_utils.py:502] loading file ../bin/models/0_BERT/added_tokens.json\n",
      "I0707 15:01:03.389424 140149010638656 tokenization_utils.py:502] loading file ../bin/models/0_BERT/special_tokens_map.json\n",
      "I0707 15:01:03.390135 140149010638656 tokenization_utils.py:502] loading file None\n",
      "I0707 15:01:03.480015 140149010638656 SentenceTransformer.py:88] Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "generic_bert_model = SentenceTransformer('../bin/models/')\n",
    "\n",
    "def bert_doc_embed(idx):\n",
    "    return bert_embeddings[idx].tolist()\n",
    "\n",
    "def bert_query_embed(query):\n",
    "    bert_vec = generic_bert_model.encode([query],show_progress_bar=False)\n",
    "    return bert_vec[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_doc_embed(idx):\n",
    "    doc_vec = centroid_matrix[idx,]\n",
    "    if(sum(doc_vec)==0): #to avoid all zeros (cosine similarity)\n",
    "        doc_vec = doc_vec + 1e-6\n",
    "    return doc_vec.tolist()\n",
    "\n",
    "def w2v_query_embed(query):\n",
    "    qvec = vectorizer.transform([query]).toarray()\n",
    "    qvec = qvec[:,idx_present]\n",
    "    qvec_transformed = np.matmul(qvec,word_embeddings)[0]\n",
    "    if(sum(qvec_transformed)==0): #to avoid all zeros (cosine similarity)\n",
    "        qvec_transformed = qvec_transformed + 1e-6\n",
    "    return qvec_transformed.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0708 08:50:59.138453 140149010638656 configuration_utils.py:281] loading configuration file ../bin/models/scibert_scivocab_uncased/config.json\n",
      "I0708 08:50:59.139977 140149010638656 configuration_utils.py:319] Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "I0708 08:50:59.141608 140149010638656 modeling_utils.py:505] loading weights file ../bin/models/scibert_scivocab_uncased/pytorch_model.bin\n",
      "I0708 08:51:03.937031 140149010638656 configuration_utils.py:281] loading configuration file ../bin/models/scibert_scivocab_uncased/config.json\n",
      "I0708 08:51:03.938997 140149010638656 configuration_utils.py:319] Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "I0708 08:51:03.940094 140149010638656 tokenization_utils.py:417] Model name '../bin/models/scibert_scivocab_uncased/' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '../bin/models/scibert_scivocab_uncased/' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0708 08:51:03.941700 140149010638656 tokenization_utils.py:449] Didn't find file ../bin/models/scibert_scivocab_uncased/added_tokens.json. We won't load it.\n",
      "I0708 08:51:03.942521 140149010638656 tokenization_utils.py:449] Didn't find file ../bin/models/scibert_scivocab_uncased/special_tokens_map.json. We won't load it.\n",
      "I0708 08:51:03.943323 140149010638656 tokenization_utils.py:449] Didn't find file ../bin/models/scibert_scivocab_uncased/tokenizer_config.json. We won't load it.\n",
      "I0708 08:51:03.944109 140149010638656 tokenization_utils.py:502] loading file ../bin/models/scibert_scivocab_uncased/vocab.txt\n",
      "I0708 08:51:03.944767 140149010638656 tokenization_utils.py:502] loading file None\n",
      "I0708 08:51:03.945497 140149010638656 tokenization_utils.py:502] loading file None\n",
      "I0708 08:51:03.946194 140149010638656 tokenization_utils.py:502] loading file None\n"
     ]
    }
   ],
   "source": [
    "scibert_model = BertModel.from_pretrained(\"../bin/models/scibert_scivocab_uncased/\")\n",
    "scibert_tokenizer = AutoTokenizer.from_pretrained(\"../bin/models/scibert_scivocab_uncased/\")\n",
    "device = torch.device(\"cpu\")\n",
    "scibert_model.to(device)\n",
    "\n",
    "def scibert_doc_embed(idx):\n",
    "    return scibert_embeddings[idx][0].tolist()\n",
    "\n",
    "def scibert_query_embed(query):\n",
    "    # Add special tokens takes care of adding [CLS], [SEP], <s>... tokens in the right way for each model.\n",
    "    input_ids = torch.tensor([scibert_tokenizer.encode(query,add_special_tokens=True, max_length=512)],device=device)\n",
    "#     try:\n",
    "    with torch.no_grad():\n",
    "        last_hidden_states = scibert_model(input_ids)  # Models outputs are now tuples\n",
    "        test = last_hidden_states[0].mean(1).detach()\n",
    "    return test.cpu()[0].tolist()\n",
    "#     except Exception as e:\n",
    "#         print(e)\n",
    "#         print(f'Was not able to get embeddings for {query}')\n",
    "#         return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def d2v_doc_embed(idx):\n",
    "    doc_vec = docvecs[idx]\n",
    "    if(sum(doc_vec)==0): #to avoid all zeros (cosine similarity)\n",
    "        doc_vec = doc_vec + 1e-6\n",
    "    return doc_vec.tolist()\n",
    "\n",
    "def d2v_query_embed(query):\n",
    "    tokens = gensim.parsing.preprocess_string(query)\n",
    "    qvec = doc2vec_model.infer_vector(tokens, steps=50, alpha=0.025)\n",
    "    return qvec.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T14:51:01.889306Z",
     "start_time": "2020-05-08T14:51:01.885312Z"
    }
   },
   "source": [
    "## Loading Saved Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load models and vectors for topic modeling\n",
    "with open('../models/tm_vectors.pkl', 'rb') as f:\n",
    "    tm_output = pickle.load(f)\n",
    "    \n",
    "with open('../models/tm_vectorizer.pkl', 'rb') as f:\n",
    "    vectorizer = pickle.load(f)\n",
    "\n",
    "with open('../models/tm_svd_model.pkl', 'rb') as f:\n",
    "    svd_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load models and vectors for TF-IDF\n",
    "with open('../models/tfidf_dict.pkl', 'rb') as f:\n",
    "    dictionary = pickle.load(f)\n",
    "    \n",
    "with open('../models/tfidf_lsi.pkl', 'rb') as f:\n",
    "    lsi = pickle.load(f)\n",
    "\n",
    "with open('../models/tfidf_vectors.pkl', 'rb') as f:\n",
    "    corpus_lsi = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T12:04:22.702086Z",
     "start_time": "2020-05-08T12:04:21.948751Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Load already saved BERT embeddings from models folder\n",
    "with open('../models/bert_corpus_embed.pkl', 'rb') as f:\n",
    "    bert_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../models/centroid_vectors.pkl', 'rb') as f:\n",
    "    centroid_matrix = pickle.load(f)\n",
    "    \n",
    "with open('../models/word_embeddings.pkl', 'rb') as f:\n",
    "    word_embeddings = pickle.load(f)\n",
    "\n",
    "with open('../models/common_vocab_idx.pkl', 'rb') as f:\n",
    "    idx_present = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load already saved SciBERT embeddings from models folder\n",
    "with open('../models/scibert_corpus_embed.pkl', 'rb') as f:\n",
    "    scibert_embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save models and vectors for the corpus for word2vec\n",
    "with open('../models/d2v_model.pkl', 'rb') as f:\n",
    "    doc2vec_model = pickle.load(f)\n",
    "    \n",
    "with open('../models/d2v_vectors.pkl', 'rb') as f:\n",
    "    docvecs = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-05-08T08:56:57.816717Z",
     "start_time": "2020-05-08T08:56:57.813712Z"
    }
   },
   "source": [
    "### Indexing and Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0708 11:24:03.564091 140149010638656 base.py:117] DELETE http://localhost:9200/docs [status:200 request:0.074s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the index.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0708 11:24:03.696436 140149010638656 base.py:117] PUT http://localhost:9200/docs [status:200 request:0.130s]\n",
      "I0708 11:24:24.686377 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:1.140s]\n",
      "I0708 11:24:27.087969 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.897s]\n",
      "I0708 11:24:29.467203 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.884s]\n",
      "I0708 11:24:31.868253 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.923s]\n",
      "I0708 11:24:34.311772 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.960s]\n",
      "I0708 11:24:36.744939 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.956s]\n",
      "I0708 11:24:39.164820 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.931s]\n",
      "I0708 11:24:41.587873 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.922s]\n",
      "I0708 11:24:44.203240 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:1.007s]\n",
      "I0708 11:24:46.687458 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.970s]\n",
      "I0708 11:24:49.078203 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.879s]\n",
      "I0708 11:24:51.486774 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.918s]\n",
      "I0708 11:24:53.870069 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.897s]\n",
      "I0708 11:24:56.324739 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.953s]\n",
      "I0708 11:24:58.671569 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.870s]\n",
      "I0708 11:25:01.047900 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.868s]\n",
      "I0708 11:25:03.594990 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.994s]\n",
      "I0708 11:25:06.050479 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.921s]\n",
      "I0708 11:25:08.443377 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.897s]\n",
      "I0708 11:25:10.779302 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.876s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 10000 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0708 11:25:33.077422 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.841s]\n",
      "I0708 11:25:35.438446 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.914s]\n",
      "I0708 11:25:37.754664 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.885s]\n",
      "I0708 11:25:40.229357 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:1.017s]\n",
      "I0708 11:25:42.578551 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.919s]\n",
      "I0708 11:25:44.970600 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.921s]\n",
      "I0708 11:25:47.353524 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.908s]\n",
      "I0708 11:25:49.710479 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.898s]\n",
      "I0708 11:25:52.028752 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.864s]\n",
      "I0708 11:25:54.358718 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.867s]\n",
      "I0708 11:25:56.769903 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.944s]\n",
      "I0708 11:25:59.112001 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.881s]\n",
      "I0708 11:26:01.429843 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.873s]\n",
      "I0708 11:26:03.815455 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.912s]\n",
      "I0708 11:26:06.174499 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.909s]\n",
      "I0708 11:26:08.654298 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.992s]\n",
      "I0708 11:26:11.076837 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.923s]\n",
      "I0708 11:26:13.449221 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.921s]\n",
      "I0708 11:26:15.825630 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.891s]\n",
      "I0708 11:26:18.153286 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.881s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 20000 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0708 11:26:41.607923 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.965s]\n",
      "I0708 11:26:44.011717 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.903s]\n",
      "I0708 11:26:46.412694 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.940s]\n",
      "I0708 11:26:48.892685 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.988s]\n",
      "I0708 11:26:51.264645 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.946s]\n",
      "I0708 11:26:53.633738 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.930s]\n",
      "I0708 11:26:56.000675 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.946s]\n",
      "I0708 11:26:58.413725 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.984s]\n",
      "I0708 11:27:00.849692 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.994s]\n",
      "I0708 11:27:03.188930 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.919s]\n",
      "I0708 11:27:05.472154 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.857s]\n",
      "I0708 11:27:07.770167 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.873s]\n",
      "I0708 11:27:10.077628 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.872s]\n",
      "I0708 11:27:12.474541 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.901s]\n",
      "I0708 11:27:14.793019 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.870s]\n",
      "I0708 11:27:17.263798 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:1.008s]\n",
      "I0708 11:27:19.589735 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.882s]\n",
      "I0708 11:27:21.934221 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.917s]\n",
      "I0708 11:27:24.335566 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.926s]\n",
      "I0708 11:27:26.710196 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.930s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 30000 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0708 11:27:48.778278 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.872s]\n",
      "I0708 11:27:51.133156 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.877s]\n",
      "I0708 11:27:53.541770 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.945s]\n",
      "I0708 11:27:55.837228 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.876s]\n",
      "I0708 11:27:58.222113 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.947s]\n",
      "I0708 11:28:00.549819 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.887s]\n",
      "I0708 11:28:02.839428 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.852s]\n",
      "I0708 11:28:05.275180 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.916s]\n",
      "I0708 11:28:07.623777 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.892s]\n",
      "I0708 11:28:09.933202 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.874s]\n",
      "I0708 11:28:12.230900 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.863s]\n",
      "I0708 11:28:14.637103 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.919s]\n",
      "I0708 11:28:17.013875 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.924s]\n",
      "I0708 11:28:19.319289 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.861s]\n",
      "I0708 11:28:21.630680 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.879s]\n",
      "I0708 11:28:23.956021 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.871s]\n",
      "I0708 11:28:26.260867 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.869s]\n",
      "I0708 11:28:28.703756 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:1.008s]\n",
      "I0708 11:28:31.122850 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.977s]\n",
      "I0708 11:28:33.482740 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.902s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 40000 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0708 11:28:56.909611 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:1.000s]\n",
      "I0708 11:28:59.388112 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.953s]\n",
      "I0708 11:29:01.738186 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.892s]\n",
      "I0708 11:29:04.151578 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.952s]\n",
      "I0708 11:29:06.569805 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.953s]\n",
      "I0708 11:29:09.134556 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.959s]\n",
      "I0708 11:29:11.631788 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.931s]\n",
      "I0708 11:29:14.036104 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.947s]\n",
      "I0708 11:29:16.393944 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.882s]\n",
      "I0708 11:29:18.794844 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.905s]\n",
      "I0708 11:29:21.158917 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.888s]\n",
      "I0708 11:29:23.580029 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.946s]\n",
      "I0708 11:29:25.955231 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.867s]\n",
      "I0708 11:29:28.391099 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.919s]\n",
      "I0708 11:29:30.778607 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.894s]\n",
      "I0708 11:29:33.304815 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.980s]\n",
      "I0708 11:29:35.690830 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.911s]\n",
      "I0708 11:29:38.049731 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.881s]\n",
      "I0708 11:29:40.427170 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.914s]\n",
      "I0708 11:29:42.881049 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.950s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 50000 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0708 11:30:06.117877 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.856s]\n",
      "I0708 11:30:08.554373 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.966s]\n",
      "I0708 11:30:10.904803 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.895s]\n",
      "I0708 11:30:13.245454 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.878s]\n",
      "I0708 11:30:15.724876 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.966s]\n",
      "I0708 11:30:18.121310 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.902s]\n",
      "I0708 11:30:20.560724 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.899s]\n",
      "I0708 11:30:22.908934 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.877s]\n",
      "I0708 11:30:25.291285 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.934s]\n",
      "I0708 11:30:27.647916 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.901s]\n",
      "I0708 11:30:30.022659 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.899s]\n",
      "I0708 11:30:32.484494 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.921s]\n",
      "I0708 11:30:34.867145 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.943s]\n",
      "I0708 11:30:37.292455 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.967s]\n",
      "I0708 11:30:39.652593 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.911s]\n",
      "I0708 11:30:42.024212 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.888s]\n",
      "I0708 11:30:44.514949 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.944s]\n",
      "I0708 11:30:46.902858 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.912s]\n",
      "I0708 11:30:49.301475 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.933s]\n",
      "I0708 11:30:51.790696 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:1.016s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 60000 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0708 11:31:13.583811 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.911s]\n",
      "I0708 11:31:15.980944 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.878s]\n",
      "I0708 11:31:18.480574 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.974s]\n",
      "I0708 11:31:20.962885 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.962s]\n",
      "I0708 11:31:23.372315 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.910s]\n",
      "I0708 11:31:25.714727 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.865s]\n",
      "I0708 11:31:28.030007 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.865s]\n",
      "I0708 11:31:30.512045 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:1.054s]\n",
      "I0708 11:31:32.922219 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.924s]\n",
      "I0708 11:31:35.266390 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.883s]\n",
      "I0708 11:31:37.578445 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.872s]\n",
      "I0708 11:31:39.943424 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.906s]\n",
      "I0708 11:31:42.304082 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.888s]\n",
      "I0708 11:31:44.722907 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.950s]\n",
      "I0708 11:31:47.179835 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.952s]\n",
      "I0708 11:31:49.564547 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.937s]\n",
      "I0708 11:31:51.902735 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.883s]\n",
      "I0708 11:31:54.337406 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.963s]\n",
      "I0708 11:31:56.833167 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.983s]\n",
      "I0708 11:31:59.265353 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.909s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 70000 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0708 11:32:22.662954 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.885s]\n",
      "I0708 11:32:25.122667 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.934s]\n",
      "I0708 11:32:27.488504 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.879s]\n",
      "I0708 11:32:29.869364 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.866s]\n",
      "I0708 11:32:32.264664 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.906s]\n",
      "I0708 11:32:34.694537 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.941s]\n",
      "I0708 11:32:37.225919 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.932s]\n",
      "I0708 11:32:39.605862 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.893s]\n",
      "I0708 11:32:41.978754 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.895s]\n",
      "I0708 11:32:44.446426 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.978s]\n",
      "I0708 11:32:46.897912 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.921s]\n",
      "I0708 11:32:49.395745 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.982s]\n",
      "I0708 11:32:51.757178 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.896s]\n",
      "I0708 11:32:54.111475 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.880s]\n",
      "I0708 11:32:56.516006 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.915s]\n",
      "I0708 11:32:58.960426 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.938s]\n",
      "I0708 11:33:01.331602 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.863s]\n",
      "I0708 11:33:03.712491 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.906s]\n",
      "I0708 11:33:06.122173 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.908s]\n",
      "I0708 11:33:08.480896 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.891s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 80000 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0708 11:33:31.279854 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.880s]\n",
      "I0708 11:33:33.659977 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.914s]\n",
      "I0708 11:33:36.026925 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.855s]\n",
      "I0708 11:33:38.350382 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.877s]\n",
      "I0708 11:33:40.691431 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.861s]\n",
      "I0708 11:33:43.106203 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.888s]\n",
      "I0708 11:33:45.630390 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.882s]\n",
      "I0708 11:33:48.068383 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.925s]\n",
      "I0708 11:33:50.553371 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.967s]\n",
      "I0708 11:33:53.135545 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.915s]\n",
      "I0708 11:33:55.558625 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.914s]\n",
      "I0708 11:33:58.008157 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.895s]\n",
      "I0708 11:34:00.454490 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.916s]\n",
      "I0708 11:34:02.840416 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.892s]\n",
      "I0708 11:34:05.272299 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.909s]\n",
      "I0708 11:34:07.813166 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.926s]\n",
      "I0708 11:34:10.243914 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.877s]\n",
      "I0708 11:34:12.692565 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.878s]\n",
      "I0708 11:34:15.078197 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.855s]\n",
      "I0708 11:34:17.539769 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.945s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 90000 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0708 11:34:39.687284 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.899s]\n",
      "I0708 11:34:42.087421 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.884s]\n",
      "I0708 11:34:44.553508 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.936s]\n",
      "I0708 11:34:46.987158 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.891s]\n",
      "I0708 11:34:49.446610 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.949s]\n",
      "I0708 11:34:52.003087 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:1.042s]\n",
      "I0708 11:34:54.378403 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.862s]\n",
      "I0708 11:34:56.787267 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.897s]\n",
      "I0708 11:34:59.124922 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.853s]\n",
      "I0708 11:35:01.569555 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.959s]\n",
      "I0708 11:35:03.921343 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.862s]\n",
      "I0708 11:35:06.349591 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.951s]\n",
      "I0708 11:35:08.782753 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.954s]\n",
      "I0708 11:35:11.217854 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.915s]\n",
      "I0708 11:35:13.593710 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.874s]\n",
      "I0708 11:35:16.018839 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.918s]\n",
      "I0708 11:35:18.367968 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.867s]\n",
      "I0708 11:35:20.785257 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.884s]\n",
      "I0708 11:35:23.320565 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.949s]\n",
      "I0708 11:35:25.756069 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.889s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 100000 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0708 11:35:37.358636 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.889s]\n",
      "I0708 11:35:40.711387 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:1.853s]\n",
      "I0708 11:35:43.081490 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.903s]\n",
      "I0708 11:35:45.448853 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.870s]\n",
      "I0708 11:35:48.082733 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:1.152s]\n",
      "I0708 11:35:50.421741 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.878s]\n",
      "I0708 11:35:52.693308 140149010638656 base.py:117] POST http://localhost:9200/_bulk [status:200 request:0.830s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexed 103482 documents.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0708 11:35:52.900137 140149010638656 base.py:117] POST http://localhost:9200/docs/_refresh [status:200 request:0.201s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done indexing.\n",
      "Time taken for indexing: 709.6641943454742 seconds\n"
     ]
    }
   ],
   "source": [
    "INDEX_NAME = \"docs\"\n",
    "INDEX_FILE = \"../resources/index.json\"\n",
    "\n",
    "DATA_FILE = \"../data/cleaned_abstracts.json\"\n",
    "BATCH_SIZE = 10000\n",
    "\n",
    "SEARCH_SIZE = 10\n",
    "\n",
    "GPU_LIMIT = 0.5\n",
    "\n",
    "client = Elasticsearch()\n",
    "\n",
    "start_time = time.time()\n",
    "index_data()\n",
    "print('Time taken for indexing:', time.time()-start_time, 'seconds')\n",
    "\n",
    "#run_query_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extractive Text Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 09:13:15.733747 140149010638656 configuration_utils.py:281] loading configuration file ../bin/models/bert/config.json\n",
      "I0715 09:13:15.735370 140149010638656 configuration_utils.py:319] Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "I0715 09:13:15.737277 140149010638656 configuration_utils.py:281] loading configuration file ../bin/models/bert/config.json\n",
      "I0715 09:13:15.738441 140149010638656 configuration_utils.py:319] Model config BertConfig {\n",
      "  \"_num_labels\": 2,\n",
      "  \"architectures\": null,\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bad_words_ids\": null,\n",
      "  \"bos_token_id\": null,\n",
      "  \"decoder_start_token_id\": null,\n",
      "  \"do_sample\": false,\n",
      "  \"early_stopping\": false,\n",
      "  \"eos_token_id\": null,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"is_encoder_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"length_penalty\": 1.0,\n",
      "  \"max_length\": 20,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"min_length\": 0,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"no_repeat_ngram_size\": 0,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_beams\": 1,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_return_sequences\": 1,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"prefix\": null,\n",
      "  \"pruned_heads\": {},\n",
      "  \"repetition_penalty\": 1.0,\n",
      "  \"task_specific_params\": null,\n",
      "  \"temperature\": 1.0,\n",
      "  \"top_k\": 50,\n",
      "  \"top_p\": 1.0,\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 31090\n",
      "}\n",
      "\n",
      "I0715 09:13:15.739089 140149010638656 tokenization_utils.py:417] Model name '../bin/models/bert' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming '../bin/models/bert' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0715 09:13:15.740628 140149010638656 tokenization_utils.py:449] Didn't find file ../bin/models/bert/added_tokens.json. We won't load it.\n",
      "I0715 09:13:15.741428 140149010638656 tokenization_utils.py:449] Didn't find file ../bin/models/bert/special_tokens_map.json. We won't load it.\n",
      "I0715 09:13:15.742233 140149010638656 tokenization_utils.py:449] Didn't find file ../bin/models/bert/tokenizer_config.json. We won't load it.\n",
      "I0715 09:13:15.743005 140149010638656 tokenization_utils.py:502] loading file ../bin/models/bert/vocab.txt\n",
      "I0715 09:13:15.743642 140149010638656 tokenization_utils.py:502] loading file None\n",
      "I0715 09:13:15.744314 140149010638656 tokenization_utils.py:502] loading file None\n",
      "I0715 09:13:15.744942 140149010638656 tokenization_utils.py:502] loading file None\n",
      "I0715 09:13:15.799689 140149010638656 modeling_utils.py:505] loading weights file ../bin/models/bert/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "custom_config = AutoConfig.from_pretrained('../bin/models/bert/')\n",
    "custom_config.output_hidden_states = True\n",
    "custom_tokenizer = AutoTokenizer.from_pretrained('../bin/models/bert')\n",
    "custom_model = AutoModel.from_pretrained('../bin/models/bert', config=custom_config)\n",
    "summ_model = Summarizer(custom_model=custom_model, custom_tokenizer=custom_tokenizer)\n",
    "\n",
    "#Pass the concatenated text string from top docs for summarisation\n",
    "def get_summary(text):\n",
    "    body = str(text)\n",
    "#     model = Summarizer(custom_model=custom_model, custom_tokenizer=custom_tokenizer)\n",
    "    summary = summ_model(body, min_length=60, ratio=0.1)\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Searching via Flask Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
      "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0727 11:24:11.520863 140149010638656 _internal.py:113]  * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
      "I0727 11:24:19.447227 140142282270464 _internal.py:113] 10.7.28.135 - - [27/Jul/2020 11:24:19] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "E0727 11:24:20.481744 140142282270464 app.py:1891] Exception on /search [GET]\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/flask/app.py\", line 2447, in wsgi_app\n",
      "    response = self.full_dispatch_request()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/flask/app.py\", line 1953, in full_dispatch_request\n",
      "    return self.finalize_request(rv)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/flask/app.py\", line 1968, in finalize_request\n",
      "    response = self.make_response(rv)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/flask/app.py\", line 2097, in make_response\n",
      "    raise TypeError(\n",
      "TypeError: The view function did not return a valid response. The function either returned None or ended without a return statement.\n",
      "I0727 11:24:20.483536 140142282270464 _internal.py:113] 10.7.28.135 - - [27/Jul/2020 11:24:20] \"\u001b[35m\u001b[1mGET /search?q= HTTP/1.1\u001b[0m\" 500 -\n",
      "I0727 11:24:24.327914 140142282270464 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.240s]\n",
      "I0727 11:24:24.353423 140142282270464 dictionary.py:205] adding document #0 to Dictionary(0 unique tokens: [])\n",
      "I0727 11:24:24.357320 140142282270464 dictionary.py:210] built Dictionary(411 unique tokens: ['date', 'debat', 'diseas', 'exact', 'infecti']...) from 81 documents (total 1158 corpus positions)\n",
      "I0727 11:24:24.359621 140142282270464 summarizer.py:358] Building graph\n",
      "I0727 11:24:24.360500 140142282270464 summarizer.py:361] Filling graph\n",
      "I0727 11:24:24.390604 140142282270464 summarizer.py:364] Removing unreachable nodes of graph\n",
      "I0727 11:24:24.391677 140142282270464 summarizer.py:373] Pagerank graph\n",
      "I0727 11:24:24.410363 140142282270464 summarizer.py:376] Sorting pagerank scores\n",
      "I0727 11:24:24.412120 140142282270464 _internal.py:113] 10.7.28.135 - - [27/Jul/2020 11:24:24] \"\u001b[37mGET /search?q=Transmission%20dynamics%20of%20the%20virus,%20including%20the%20basic%20reproductive%20number,%20incubation%20period,%20serial%20interval,%20modes%20of%20transmission%20and%20environmental%20factors HTTP/1.1\u001b[0m\" 200 -\n"
     ]
    }
   ],
   "source": [
    "app = Flask(__name__, template_folder='../resources')\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "    return render_template('index.html')\n",
    "#     return render_template('testpage.html')\n",
    "\n",
    "\n",
    "@app.route('/search')\n",
    "def analyser():\n",
    "    query = request.args.get('q')\n",
    "    \n",
    "    if query:\n",
    "        embedding_start = time.time()\n",
    "        tm_query_vec = tm_query_embed(query)\n",
    "        tfidf_query_vec = tfidf_query_embed(query)\n",
    "        bert_query_vec = bert_query_embed(query)\n",
    "        w2v_query_vec = w2v_query_embed(query)\n",
    "        scibert_query_vec = scibert_query_embed(query)\n",
    "        d2v_query_vec = d2v_query_embed(query)\n",
    "        embedding_time = time.time() - embedding_start\n",
    "        \n",
    "        tm_cos_sim = \"cosineSimilarity(params.tm_qv, doc['tm_doc_vec']) + 1.0\"\n",
    "        tfidf_cos_sim = \"cosineSimilarity(params.tfidf_qv, doc['tfidf_doc_vec']) + 1.0\"\n",
    "        bert_cos_sim = \"cosineSimilarity(params.bert_qv, doc['bert_doc_vec']) + 1.0\"\n",
    "        w2v_cos_sim = \"cosineSimilarity(params.w2v_qv, doc['w2v_doc_vec']) + 1.0\"\n",
    "        scibert_cos_sim = \"cosineSimilarity(params.scibert_qv, doc['scibert_doc_vec']) + 1.0\"\n",
    "        d2v_cos_sim = \"cosineSimilarity(params.d2v_qv, doc['d2v_doc_vec']) + 1.0\"\n",
    "        sep = \" + \"\n",
    "        \n",
    "        #choose models to include here\n",
    "        similarity_func = d2v_cos_sim + sep + tfidf_cos_sim + sep + bert_cos_sim + sep + w2v_cos_sim\n",
    "        \n",
    "        script_query = {\n",
    "            \"script_score\": {\n",
    "                \"query\": {\"match_all\": {}},\n",
    "                \"script\": {\n",
    "                    \"source\": similarity_func,\n",
    "                    \"params\": {\"d2v_qv\": d2v_query_vec, \"scibert_qv\": scibert_query_vec, \"w2v_qv\": w2v_query_vec, \"tm_qv\": tm_query_vec, \"tfidf_qv\": tfidf_query_vec, \"bert_qv\": bert_query_vec}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        search_start = time.time()\n",
    "        response = client.search(\n",
    "            index=INDEX_NAME,\n",
    "            body={\n",
    "                \"size\": SEARCH_SIZE,\n",
    "                \"query\": script_query,\n",
    "                \"_source\": {\"includes\": [\"title\", \"abstract\", \"url\", \"authors\"]}\n",
    "            }\n",
    "        )\n",
    "        search_time = time.time() - search_start\n",
    "\n",
    "        #Call to summarizer\n",
    "        output_text = \"\"\n",
    "        for hit in response['hits']['hits']:\n",
    "            selected_text = hit['_source']['abstract']\n",
    "            output_text = output_text + \" \" + selected_text\n",
    "\n",
    "        summary = summarize(output_text)\n",
    "\n",
    "        result_disp = {\"top_docs\" : response, \"summary\" : summary}\n",
    "        return jsonify(result_disp)\n",
    "    \n",
    "    else:\n",
    "        return \n",
    "app.run(host='0.0.0.0', port=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation of results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating MRR using titles as queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to find reciprocal rank for a given query in the topk results (edit similarity_func to choose model combination)\n",
    "def find_rr(query, topk=20):\n",
    "    if query:\n",
    "        embedding_start = time.time()\n",
    "        tm_query_vec = tm_query_embed(query)\n",
    "        tfidf_query_vec = tfidf_query_embed(query)\n",
    "        bert_query_vec = bert_query_embed(query)\n",
    "        w2v_query_vec = w2v_query_embed(query)\n",
    "        scibert_query_vec = scibert_query_embed(query)\n",
    "        d2v_query_vec = d2v_query_embed(query)\n",
    "        embedding_time = time.time() - embedding_start\n",
    "        \n",
    "        tm_cos_sim = \"cosineSimilarity(params.tm_qv, doc['tm_doc_vec']) + 1.0\"\n",
    "        tfidf_cos_sim = \"cosineSimilarity(params.tfidf_qv, doc['tfidf_doc_vec']) + 1.0\"\n",
    "        bert_cos_sim = \"cosineSimilarity(params.bert_qv, doc['bert_doc_vec']) + 1.0\"\n",
    "        w2v_cos_sim = \"cosineSimilarity(params.w2v_qv, doc['w2v_doc_vec']) + 1.0\"\n",
    "        scibert_cos_sim = \"cosineSimilarity(params.scibert_qv, doc['scibert_doc_vec']) + 1.0\"\n",
    "        d2v_cos_sim = \"cosineSimilarity(params.d2v_qv, doc['d2v_doc_vec']) + 1.0\"\n",
    "        sep = \" + \"\n",
    "        \n",
    "        #choose models to include here\n",
    "        similarity_func = d2v_cos_sim + sep + tfidf_cos_sim + sep + bert_cos_sim\n",
    "#         similarity_func = bert_cos_sim \n",
    "        \n",
    "        script_query = {\n",
    "            \"script_score\": {\n",
    "                \"query\": {\"match_all\": {}},\n",
    "                \"script\": {\n",
    "                    \"source\": similarity_func,\n",
    "                    \"params\": {\"d2v_qv\": d2v_query_vec, \"scibert_qv\": scibert_query_vec, \"w2v_qv\": w2v_query_vec, \"tm_qv\": tm_query_vec, \"tfidf_qv\": tfidf_query_vec, \"bert_qv\": bert_query_vec}\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "\n",
    "        search_start = time.time()\n",
    "        response = client.search(\n",
    "            index=INDEX_NAME,\n",
    "            body={\n",
    "                \"size\": topk,\n",
    "                \"query\": script_query,\n",
    "                \"_source\": {\"includes\": [\"title\", \"abstract\", \"url\", \"authors\"]}\n",
    "            }\n",
    "        )\n",
    "        search_time = time.time() - search_start\n",
    "        \n",
    "        rr = 0\n",
    "        for i, hit in enumerate(response['hits']['hits']):\n",
    "            if (query == hit['_source']['title']):\n",
    "                rr = 1/(i+1)\n",
    "                break\n",
    "                \n",
    "        return rr, embedding_time, search_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 09:59:16.636134 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.204s]\n",
      "I0715 09:59:16.942436 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 09:59:17.247847 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 09:59:17.584470 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 09:59:17.886944 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 09:59:18.184077 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 09:59:18.503269 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.198s]\n",
      "I0715 09:59:18.789981 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 09:59:19.092944 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 09:59:19.389391 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 09:59:19.762063 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 09:59:20.084333 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 09:59:20.382272 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 09:59:20.679887 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 09:59:20.977656 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 09:59:21.277393 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 09:59:21.582682 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 09:59:21.922102 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 09:59:22.214279 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 09:59:22.503641 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 09:59:22.790782 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 09:59:23.093958 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 09:59:23.390212 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 09:59:23.688109 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 09:59:24.013078 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 09:59:24.393712 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 09:59:24.687487 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 09:59:24.991075 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 09:59:25.296530 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 09:59:25.611679 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 09:59:25.908558 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 09:59:26.283168 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 09:59:26.567550 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 09:59:26.861550 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 09:59:27.145903 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 09:59:27.449571 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 09:59:27.761143 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 09:59:28.062598 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 09:59:28.362901 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 09:59:28.652214 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.176s]\n",
      "I0715 09:59:28.950529 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 09:59:29.317616 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 09:59:29.643541 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 09:59:29.956953 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 09:59:30.297315 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 09:59:30.636158 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 09:59:30.966889 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.204s]\n",
      "I0715 09:59:31.281381 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 09:59:31.587682 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 09:59:31.900981 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 09:59:32.221654 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 09:59:32.524221 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 09:59:32.825765 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 09:59:33.116571 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 09:59:33.411457 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 09:59:33.723978 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 09:59:34.074442 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.202s]\n",
      "I0715 09:59:34.396138 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 09:59:34.716099 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 09:59:35.036648 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 09:59:35.347135 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 09:59:35.662359 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.201s]\n",
      "I0715 09:59:35.962054 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 09:59:36.299669 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.209s]\n",
      "I0715 09:59:36.610642 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 09:59:37.023107 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 09:59:37.318512 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 09:59:37.621784 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 09:59:37.942104 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 09:59:38.247943 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 09:59:38.584737 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 09:59:38.888407 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 09:59:39.222038 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 09:59:39.545061 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 09:59:39.852816 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 09:59:40.166856 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.199s]\n",
      "I0715 09:59:40.477202 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 09:59:40.776271 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 09:59:41.096950 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 09:59:41.410052 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 09:59:41.710399 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 09:59:42.005840 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 09:59:42.312550 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 09:59:42.619087 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 09:59:42.904568 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 09:59:43.234135 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.200s]\n",
      "I0715 09:59:43.526673 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 09:59:43.821856 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 09:59:44.118043 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 09:59:44.416099 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 09:59:44.713404 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 09:59:45.013213 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 09:59:45.327716 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.197s]\n",
      "I0715 09:59:45.651390 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.202s]\n",
      "I0715 09:59:45.981174 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.208s]\n",
      "I0715 09:59:46.307193 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.210s]\n",
      "I0715 09:59:46.813865 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 09:59:47.152868 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 09:59:47.471441 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 09:59:47.798216 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 09:59:48.118515 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 09:59:48.531098 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.198s]\n",
      "I0715 09:59:48.874617 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 09:59:49.222990 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.197s]\n",
      "I0715 09:59:49.533231 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 09:59:49.848009 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.201s]\n",
      "I0715 09:59:50.139804 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 09:59:50.428166 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 09:59:50.805745 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 09:59:51.107646 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 09:59:51.402245 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.177s]\n",
      "I0715 09:59:51.688139 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 09:59:52.060380 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 09:59:52.358641 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 09:59:52.738245 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 09:59:53.052702 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 09:59:53.354920 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 09:59:53.732790 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 09:59:54.081508 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 09:59:54.405435 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 09:59:54.722211 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 09:59:55.036506 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 09:59:55.428362 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.211s]\n",
      "I0715 09:59:55.730984 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 09:59:56.034138 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 09:59:56.324935 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 09:59:56.726972 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 09:59:57.070167 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 09:59:57.392202 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 09:59:57.730094 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.204s]\n",
      "I0715 09:59:58.051929 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 09:59:58.391203 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 09:59:58.679919 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 09:59:58.996973 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 09:59:59.295379 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 09:59:59.583996 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:00:00.125566 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:00:00.452987 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.177s]\n",
      "I0715 10:00:00.777752 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:00:01.102837 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.200s]\n",
      "I0715 10:00:01.439973 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:00:01.750259 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:00:02.082248 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:00:02.391793 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:00:02.710145 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:00:03.024575 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:00:03.342483 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:00:03.682029 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:00:04.065651 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:00:04.377786 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:00:04.696119 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:00:04.988828 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.175s]\n",
      "I0715 10:00:05.318731 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:00:05.629575 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:00:06.129729 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:00:06.434206 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:00:06.726405 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.177s]\n",
      "I0715 10:00:07.019670 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:00:07.327295 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:00:07.733251 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:00:08.032836 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:00:08.319074 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.175s]\n",
      "I0715 10:00:08.607016 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:00:08.923251 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:00:09.218626 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:00:09.522275 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:00:09.825280 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.177s]\n",
      "I0715 10:00:10.191814 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:00:10.543505 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:00:10.848653 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:00:11.165320 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:00:11.493344 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:00:11.810235 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:00:12.131139 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:00:12.431967 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:00:12.728568 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:00:13.051220 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.200s]\n",
      "I0715 10:00:13.355598 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:00:13.747704 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:00:14.059611 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:00:14.360681 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:00:14.668604 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:00:14.961841 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:00:15.450265 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:00:15.765873 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:00:16.060504 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:00:16.366640 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:00:16.666287 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:00:16.992712 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:00:17.306861 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:00:17.655432 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:00:18.040999 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 10:00:18.335631 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:00:18.628058 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:00:18.967831 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.202s]\n",
      "I0715 10:00:19.321255 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:00:19.658607 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:00:19.991952 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.198s]\n",
      "I0715 10:00:20.304694 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:00:20.610762 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.199s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:00:20.939037 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:00:21.269016 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:00:21.593097 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:00:21.901836 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:00:22.230304 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.197s]\n",
      "I0715 10:00:22.557034 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 10:00:22.864130 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:00:23.171424 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 10:00:23.490894 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:00:23.858323 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:00:24.237072 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.201s]\n",
      "I0715 10:00:24.563948 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:00:24.871006 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:00:25.162135 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:00:25.478505 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:00:25.781557 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:00:26.067312 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:00:26.355884 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:00:26.643380 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:00:26.924451 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:00:27.232753 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:00:27.536533 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:00:27.833386 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:00:28.131965 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:00:28.477100 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:00:28.783105 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:00:29.281875 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:00:29.671561 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:00:29.959745 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:00:30.257301 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:00:30.585546 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:00:30.903507 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:00:31.235369 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:00:31.540601 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:00:31.860302 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.204s]\n",
      "I0715 10:00:32.166489 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:00:32.482796 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:00:32.799523 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:00:33.122753 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:00:33.429605 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:00:33.733100 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:00:34.050121 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.199s]\n",
      "I0715 10:00:34.347188 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:00:34.647912 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:00:34.964360 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.202s]\n",
      "I0715 10:00:35.524517 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:00:35.834577 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:00:36.231242 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:00:36.766647 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:00:37.071320 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:00:37.438745 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:00:37.747097 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:00:38.065283 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 10:00:38.402039 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.198s]\n",
      "I0715 10:00:38.704351 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:00:39.103333 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.201s]\n",
      "I0715 10:00:39.434054 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:00:39.736549 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:00:40.046379 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:00:40.350148 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.198s]\n",
      "I0715 10:00:40.643860 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:00:40.947018 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:00:41.294395 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:00:41.612675 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:00:41.898403 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:00:42.192895 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:00:42.475748 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:00:42.799816 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:00:43.109018 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:00:43.423819 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:00:43.748319 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:00:44.059580 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:00:44.378105 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.177s]\n",
      "I0715 10:00:44.685174 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:00:45.115767 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:00:45.440958 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:00:45.741094 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:00:46.048059 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:00:46.365478 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:00:46.670431 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:00:46.976711 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:00:47.281327 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:00:47.570482 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:00:47.869840 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:00:48.186460 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.204s]\n",
      "I0715 10:00:48.566248 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:00:48.881839 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:00:49.213403 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:00:49.515705 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:00:49.838272 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.198s]\n",
      "I0715 10:00:50.152704 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:00:50.465524 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:00:50.806679 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:00:51.151101 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:00:51.527541 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:00:51.853850 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:00:52.182729 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:00:52.536275 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.210s]\n",
      "I0715 10:00:52.902386 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:00:53.220913 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:00:53.558895 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:00:53.892428 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:00:54.197854 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:00:54.513282 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:00:54.840099 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.203s]\n",
      "I0715 10:00:55.159186 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:00:55.467224 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:00:55.785732 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:00:56.097991 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:00:56.397503 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:00:56.726225 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.208s]\n",
      "I0715 10:00:57.026740 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:00:57.329856 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:00:57.628278 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:00:57.932293 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:00:58.240811 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:00:58.533686 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:00:58.846188 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:00:59.163096 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:00:59.532690 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.177s]\n",
      "I0715 10:00:59.903264 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:01:00.221118 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:01:00.540656 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:01:00.864317 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:01:01.265069 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:01:01.581348 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:01:01.905250 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:01:02.223290 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:01:02.539230 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:01:02.852087 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:01:03.176264 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:01:03.493342 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.201s]\n",
      "I0715 10:01:03.787643 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:04.083254 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:01:04.375395 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:01:04.684810 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:01:05.013501 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.203s]\n",
      "I0715 10:01:05.322233 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:01:05.662021 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:01:05.973360 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:01:06.284162 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:01:06.580053 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:01:06.887095 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:01:07.202556 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 10:01:07.526516 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.198s]\n",
      "I0715 10:01:07.822799 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:01:08.138656 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.197s]\n",
      "I0715 10:01:08.441029 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:01:08.753434 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:01:09.074970 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 10:01:09.415847 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:01:09.747772 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:01:10.062261 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:01:10.370082 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:01:10.679661 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:01:10.973954 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:01:11.268189 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:01:11.569767 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:01:11.871760 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:01:12.161485 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:01:12.467873 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 10:01:12.984683 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:13.295132 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:01:13.594712 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:01:13.892575 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.177s]\n",
      "I0715 10:01:14.204098 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:01:14.516680 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:01:14.836349 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:01:15.339995 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:01:15.663330 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.201s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:01:15.994292 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:16.313211 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:01:16.685378 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:01:17.078302 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:01:17.400734 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:01:17.725008 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:01:18.108032 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:01:18.426303 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:01:18.809200 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:01:19.143431 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:19.469741 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:01:19.816273 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:01:20.160126 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 10:01:20.466745 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:01:20.774767 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:01:21.086868 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:01:21.409552 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:01:21.799680 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:01:22.097727 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:01:22.400567 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:01:22.732503 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.203s]\n",
      "I0715 10:01:23.055314 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:01:23.377291 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 10:01:23.692248 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:24.009936 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:01:24.332560 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:01:24.695868 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:01:25.010370 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:01:25.328503 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 10:01:25.665377 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.203s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:01:25.977411 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:01:26.304103 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:01:26.640372 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:01:26.969425 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:01:27.266829 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:27.596783 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:01:28.001995 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:01:28.304457 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:01:28.595406 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:01:28.897218 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:01:29.270120 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:29.583345 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:01:29.879307 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:01:30.185108 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:01:30.501870 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:01:30.812176 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:01:31.142091 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:01:31.450671 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:31.770620 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.203s]\n",
      "I0715 10:01:32.070250 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:32.371871 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:01:32.703061 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:01:33.004165 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:01:33.330281 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:01:33.638787 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:01:33.943121 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:01:34.236368 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:01:34.548328 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:34.856562 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:01:35.170917 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:01:35.472064 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:01:35.773008 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:01:36.328679 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:01:36.627934 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:01:36.934257 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:01:37.231476 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:01:37.559933 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 10:01:37.863394 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:01:38.160383 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:38.481552 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:01:38.789390 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:01:39.099909 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:01:39.397132 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:01:39.724227 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:01:40.059865 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:01:40.385729 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:01:40.703428 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:01:41.061731 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:01:41.384805 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:01:41.829218 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:01:42.142183 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:01:42.448790 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:01:42.753331 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.177s]\n",
      "I0715 10:01:43.045141 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:01:43.343472 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:01:43.639279 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:43.945431 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:01:44.246385 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:01:44.540792 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:01:44.851300 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:01:45.203048 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.208s]\n",
      "I0715 10:01:45.518973 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.202s]\n",
      "I0715 10:01:45.813735 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:01:46.108356 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:01:46.419034 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:01:46.740624 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.201s]\n",
      "I0715 10:01:47.049218 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:01:47.410280 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:01:47.723030 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:01:48.041179 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:01:48.375416 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:01:48.694302 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:01:49.006045 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:01:49.333216 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:49.646908 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:01:49.976167 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:01:50.343359 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:01:50.653695 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:01:50.959171 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:01:51.274392 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:01:51.587310 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:51.933895 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:01:52.244039 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:01:52.581806 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:01:52.883414 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:01:53.248269 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:01:53.575653 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:01:53.947469 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:01:54.239019 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:01:54.530215 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:01:54.836463 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:01:55.229678 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:01:55.520215 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:01:55.813867 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:01:56.109008 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:01:56.415105 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:01:56.709654 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:01:57.015656 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:01:57.308546 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:01:57.601543 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 6 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:01:57.902716 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:01:58.199816 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:01:58.498861 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:58.920367 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:01:59.263663 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.206s]\n",
      "I0715 10:01:59.599479 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:01:59.901544 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:02:00.223704 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:02:00.584192 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:02:00.892345 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:02:01.194894 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:02:01.487921 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:02:01.843417 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:02:02.145263 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:02:02.449818 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:02:02.769020 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:02:03.079851 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.198s]\n",
      "I0715 10:02:03.391893 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:02:03.711647 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:02:04.076816 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:02:04.375507 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:02:04.675106 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:02:04.979732 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:02:05.332341 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:02:05.680673 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:02:05.973093 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:02:06.351084 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:02:06.657747 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:02:06.966457 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:02:07.291735 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:02:07.591618 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.177s]\n",
      "I0715 10:02:07.880377 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:02:08.177692 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:02:08.644604 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:02:08.933408 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:02:09.234078 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:02:09.530381 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:02:09.833065 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:02:10.144484 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.199s]\n",
      "I0715 10:02:10.443151 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:02:10.732843 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:02:11.025398 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:02:11.381323 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:02:11.694627 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:02:12.016225 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:02:12.326031 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:02:12.622373 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:02:12.920279 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:02:13.224369 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:02:13.613856 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:02:13.913428 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:02:14.206215 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:02:14.489340 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:02:14.793693 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:02:15.101132 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:02:15.415063 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:02:15.735233 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 10:02:16.029691 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:02:16.396131 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:02:16.769215 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:02:17.097409 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:02:17.412418 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:02:17.726049 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:02:18.087933 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:02:18.581029 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:02:18.894793 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:02:19.197742 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:02:19.522576 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:02:19.849202 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:02:20.162501 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:02:20.521561 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:02:20.833362 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:02:21.140510 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:02:21.440089 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:02:21.755851 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:02:22.088447 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:02:22.396240 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:02:22.724439 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 10:02:23.038322 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 10:02:23.331908 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:02:23.651653 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:02:23.968775 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:02:24.269233 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:02:24.561511 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:02:24.931307 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 10:02:25.248946 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:02:25.581168 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.208s]\n",
      "I0715 10:02:25.887780 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:02:26.186129 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:02:26.474354 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:02:26.771064 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:02:27.072529 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:02:27.380951 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:02:27.710261 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.227s]\n",
      "I0715 10:02:28.021650 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.197s]\n",
      "I0715 10:02:28.315316 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:02:28.616863 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:02:28.919709 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:02:29.267192 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:02:29.587463 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 7 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:02:29.893767 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:02:30.194873 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:02:30.495238 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:02:30.821798 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:02:31.145308 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:02:31.445630 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:02:31.740606 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:02:32.053350 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:02:32.367421 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:02:32.750644 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:02:33.129907 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:02:33.463726 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:02:33.811227 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:02:34.108254 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:02:34.427828 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.197s]\n",
      "I0715 10:02:34.747143 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:02:35.287750 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:02:35.624843 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:02:35.953151 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.201s]\n",
      "I0715 10:02:36.262210 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.199s]\n",
      "I0715 10:02:36.564512 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:02:36.869503 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:02:37.180741 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:02:37.547681 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.199s]\n",
      "I0715 10:02:37.870680 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:02:38.229203 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:02:38.548515 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:02:38.886350 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.201s]\n",
      "I0715 10:02:39.236613 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.176s]\n",
      "I0715 10:02:39.569255 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:02:39.882670 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:02:40.177150 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:02:40.478851 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:02:40.805450 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:02:41.111001 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:02:41.429183 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.199s]\n",
      "I0715 10:02:41.731577 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:02:42.033125 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:02:42.345130 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:02:42.669466 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:02:43.118004 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:02:43.413314 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:02:43.731937 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:02:44.032627 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:02:44.327229 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:02:44.636101 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:02:44.929080 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:02:45.227462 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:02:45.524600 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:02:45.824162 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:02:46.272951 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:02:46.580781 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:02:46.893020 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:02:47.213964 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:02:47.537904 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:02:47.857684 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:02:48.247340 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:02:48.601262 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:02:49.042797 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 10:02:49.346782 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:02:49.664015 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:02:49.988688 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:02:50.417725 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:02:50.751909 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 10:02:51.055978 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:02:51.393924 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.207s]\n",
      "I0715 10:02:51.698858 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:02:52.000835 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:02:52.318266 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.212s]\n",
      "I0715 10:02:52.635247 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.198s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:02:52.950793 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.198s]\n",
      "I0715 10:02:53.254799 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:02:53.551855 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:02:53.852004 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:02:54.227219 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:02:54.535700 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:02:54.830188 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:02:55.121441 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:02:55.431805 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:02:55.741634 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:02:56.056280 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:02:56.388722 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:02:56.735814 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:02:57.070628 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:02:57.382277 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:02:57.688176 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:02:58.000593 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.199s]\n",
      "I0715 10:02:58.304706 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:02:58.624008 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:02:58.960961 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.207s]\n",
      "I0715 10:02:59.274237 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:02:59.584259 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:02:59.900642 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.199s]\n",
      "I0715 10:03:00.219997 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.205s]\n",
      "I0715 10:03:00.564105 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:03:00.895405 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:03:01.285751 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.202s]\n",
      "I0715 10:03:01.599942 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:03:01.939192 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:03:02.247475 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.197s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:03:02.560256 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 10:03:02.887798 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:03:03.207778 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.203s]\n",
      "I0715 10:03:03.499158 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:03:03.810112 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:03:04.103625 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:03:04.389471 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:03:04.686956 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:03:05.042856 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:03:05.370800 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:03:05.682128 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:03:05.995049 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:03:06.304737 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:03:06.600121 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:03:06.899949 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:03:07.202965 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 10:03:07.514374 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:03:07.856255 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:03:08.179413 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 10:03:08.473932 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:03:08.789959 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.199s]\n",
      "I0715 10:03:09.094611 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:03:09.399457 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:03:09.724967 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:03:10.045609 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:03:10.354152 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:03:10.657814 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:03:10.965075 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.201s]\n",
      "I0715 10:03:11.277351 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.199s]\n",
      "I0715 10:03:11.652252 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:03:11.997669 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:03:12.311566 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.197s]\n",
      "I0715 10:03:12.634424 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:03:12.937995 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:03:13.229286 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:03:13.536570 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:03:13.841753 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:03:14.154697 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:03:14.457435 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:03:14.758649 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:03:15.079946 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:03:15.390714 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:03:15.757078 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 10:03:16.092615 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:03:16.415903 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:03:16.749228 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:03:17.059530 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:03:17.366336 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:03:17.669542 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:03:17.970543 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:03:18.258265 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.177s]\n",
      "I0715 10:03:18.557671 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:03:18.870052 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:03:19.174670 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:03:19.507772 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.208s]\n",
      "I0715 10:03:19.828844 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:03:20.395789 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:03:20.720413 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 10:03:21.049393 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:03:21.372528 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.203s]\n",
      "I0715 10:03:21.687216 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:03:21.979102 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:03:22.341899 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:03:22.647345 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:03:22.934169 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:03:23.498781 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:03:23.806915 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:03:24.116028 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:03:24.422888 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:03:24.774008 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:03:25.068977 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:03:25.384561 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:03:25.782269 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:03:26.098645 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.197s]\n",
      "I0715 10:03:26.394313 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:03:26.781532 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:03:27.152243 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.199s]\n",
      "I0715 10:03:27.473193 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:03:27.775945 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:03:28.079189 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:03:28.367184 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.177s]\n",
      "I0715 10:03:28.703762 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:03:29.011155 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:03:29.321774 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:03:29.683043 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:03:30.014017 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:03:30.329058 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:03:30.644122 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:03:30.960423 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:03:31.284691 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:03:31.616955 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:03:31.918501 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:03:32.224656 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:03:32.554919 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:03:32.929146 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:03:33.297855 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:03:33.619442 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:03:33.962765 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:03:34.291141 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:03:34.604138 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 9 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:03:34.908559 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:03:35.243477 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.216s]\n",
      "I0715 10:03:35.546101 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:03:35.888500 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:03:36.181612 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:03:36.473277 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:03:36.829771 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:03:37.144437 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:03:37.455854 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:03:37.838234 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:03:38.139063 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:03:38.494090 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:03:38.818249 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.199s]\n",
      "I0715 10:03:39.121830 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:03:39.417136 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:03:39.862534 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:03:40.236047 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 10:03:40.566789 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.201s]\n",
      "I0715 10:03:40.888748 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:03:41.189361 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:03:41.497499 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:03:41.909565 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:03:42.221813 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.200s]\n",
      "I0715 10:03:42.526657 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:03:42.853551 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:03:43.163988 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:03:43.475056 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.198s]\n",
      "I0715 10:03:43.786008 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:03:44.096703 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:03:44.419299 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.198s]\n",
      "I0715 10:03:44.831808 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.206s]\n",
      "I0715 10:03:45.147597 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:03:45.446643 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:03:45.742854 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:03:46.024910 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:03:46.319280 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:03:46.610045 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:03:46.901719 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:03:47.206961 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:03:47.512100 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:03:47.817044 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:03:48.122426 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:03:48.424579 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:03:48.763232 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:03:49.197465 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 10:03:49.506833 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:03:49.847837 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:03:50.185412 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.197s]\n",
      "I0715 10:03:50.508376 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:03:50.814621 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:03:51.160274 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.221s]\n",
      "I0715 10:03:51.458351 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:03:51.803171 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 10:03:52.122395 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:03:52.456222 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:03:52.963254 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:03:53.286283 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:03:53.633206 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:03:53.940083 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:03:54.235874 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:03:54.539987 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:03:54.877935 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:03:55.187831 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:03:55.520474 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:03:55.839712 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.198s]\n",
      "I0715 10:03:56.209636 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.197s]\n",
      "I0715 10:03:56.521478 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:03:56.865609 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.202s]\n",
      "I0715 10:03:57.171622 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.195s]\n",
      "I0715 10:03:57.509026 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:03:57.843369 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:03:58.148857 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:03:58.459106 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:03:58.885739 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:03:59.200381 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:03:59.510032 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:03:59.813336 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:04:00.110513 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:04:00.543137 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:04:00.885323 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:04:01.186120 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:04:01.482119 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:04:01.815437 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:04:02.110786 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:04:02.405887 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:04:02.703748 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:04:03.006064 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:04:03.306429 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:04:03.619422 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:04:03.915715 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:04:04.261276 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:04:04.562958 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:04:04.876266 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:04:05.174381 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:04:05.474920 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:04:05.776479 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:04:06.079860 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.197s]\n",
      "I0715 10:04:06.381087 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:04:06.688936 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:04:06.986325 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:04:07.297820 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:04:07.607109 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.200s]\n",
      "I0715 10:04:07.901597 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:04:08.388042 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:04:08.700510 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.199s]\n",
      "I0715 10:04:09.005194 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:04:09.311671 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:04:09.615206 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:04:09.922093 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:04:10.260145 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.205s]\n",
      "I0715 10:04:10.564181 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:04:10.875461 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:04:11.190960 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:04:11.490001 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:04:11.839534 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:04:12.180480 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:04:12.467388 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.177s]\n",
      "I0715 10:04:12.779085 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.198s]\n",
      "I0715 10:04:13.072555 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:04:13.359503 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:04:13.687540 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:04:14.028084 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:04:14.370120 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:04:14.703737 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:04:15.042292 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.197s]\n",
      "I0715 10:04:15.356971 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:04:15.664338 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:04:15.960872 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:04:16.280433 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:04:16.600478 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:04:16.915103 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:04:17.209157 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:04:17.519184 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:04:17.825043 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:04:18.217775 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:04:18.533263 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:04:18.823687 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.174s]\n",
      "I0715 10:04:19.125362 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:04:19.412921 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:04:19.713316 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:04:20.030575 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:04:20.349008 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 10:04:20.740543 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:04:21.041990 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:04:21.357234 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:04:21.675025 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.198s]\n",
      "I0715 10:04:21.993202 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.197s]\n",
      "I0715 10:04:22.299514 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:04:22.716814 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 10:04:23.039198 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n",
      "I0715 10:04:23.343433 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:04:23.677378 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:04:24.030299 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:04:24.318889 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:04:24.608178 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.177s]\n",
      "I0715 10:04:24.912564 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:04:25.220799 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:04:25.510287 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:04:25.809139 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:04:26.113402 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.194s]\n",
      "I0715 10:04:26.512509 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:04:26.800374 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:04:27.102783 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:04:27.415800 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:04:27.723267 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.176s]\n",
      "I0715 10:04:28.149602 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.202s]\n",
      "I0715 10:04:28.466269 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:04:28.764401 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:04:29.063636 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.180s]\n",
      "I0715 10:04:29.415620 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.191s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0715 10:04:29.733191 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:04:30.051321 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:04:30.381744 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:04:30.690433 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.177s]\n",
      "I0715 10:04:30.993816 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.179s]\n",
      "I0715 10:04:31.317763 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n",
      "I0715 10:04:31.647501 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:04:31.964856 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:04:32.285277 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.188s]\n",
      "I0715 10:04:32.620185 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.203s]\n",
      "I0715 10:04:32.916425 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:04:33.228154 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.196s]\n",
      "I0715 10:04:33.529477 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.189s]\n",
      "I0715 10:04:33.832123 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:04:34.125679 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:04:34.506767 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:04:34.808812 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.187s]\n",
      "I0715 10:04:35.133033 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.193s]\n",
      "I0715 10:04:35.452276 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.183s]\n",
      "I0715 10:04:35.763072 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:04:36.089336 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:04:36.429309 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:04:36.797556 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.184s]\n",
      "I0715 10:04:37.124846 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.181s]\n",
      "I0715 10:04:37.493561 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.178s]\n",
      "I0715 10:04:37.799265 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.190s]\n",
      "I0715 10:04:38.092567 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.185s]\n",
      "I0715 10:04:38.389808 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.182s]\n",
      "I0715 10:04:38.687141 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.186s]\n",
      "I0715 10:04:38.995660 140149010638656 base.py:117] GET http://localhost:9200/docs/_search [status:200 request:0.192s]\n"
     ]
    }
   ],
   "source": [
    "#find MRR over a set of <query_set_size> randomly chosen titles in the <topk> results, averaged over <n_iter> runs\n",
    "n_iter = 10\n",
    "query_set_size = 100\n",
    "topk = 20\n",
    "\n",
    "avg_rr = 0\n",
    "avg_et = 0\n",
    "avg_st = 0\n",
    "    \n",
    "for j in range(n_iter):\n",
    "    print(\"Iteration\", j+1, \"of\", n_iter)\n",
    "    title_queries = list(np.random.choice(df['title'], query_set_size))\n",
    "\n",
    "    rrs = np.zeros(query_set_size)\n",
    "    ets = np.zeros(query_set_size)\n",
    "    sts = np.zeros(query_set_size)\n",
    "\n",
    "    for i, query in enumerate(title_queries):\n",
    "        rrs[i], ets[i], sts[i] = find_rr(query)\n",
    "        \n",
    "    avg_rr += np.mean(rrs)\n",
    "    avg_et += np.mean(ets)\n",
    "    avg_st += np.mean(sts)\n",
    "    \n",
    "avg_rr /= n_iter\n",
    "avg_et /= n_iter\n",
    "avg_st /= n_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reciprocal Rank (MRR) : 0.3434526698104098\n",
      "Mean embedding time : 0.13016126799583433 seconds\n",
      "Mean search time : 0.19235228180885314 seconds\n"
     ]
    }
   ],
   "source": [
    "#print MRR, mean embedding and query times\n",
    "print(\"Mean Reciprocal Rank (MRR) :\", avg_rr)\n",
    "print(\"Mean embedding time :\", avg_et, 'seconds')\n",
    "print(\"Mean search time :\", avg_st, 'seconds')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "307.2px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
